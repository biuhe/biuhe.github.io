{"title":"「Python」Python基于OpenPose实现图片中人体姿态识别","slug":"技术/python/「Python」Python基于OpenPose实现图片中人体姿态识别","date":"2023-06-15T13:51:37.000Z","updated":"2023-06-27T13:13:23.501Z","comments":true,"path":"api/articles/技术/python/「Python」Python基于OpenPose实现图片中人体姿态识别.json","excerpt":null,"covers":null,"content":"<h2 id=\"背景\"><a class=\"markdownIt-Anchor\" href=\"#背景\"></a> 背景</h2>\n<p>合作公司有个小伙伴提到之前要处理图片中对人物裁剪的效果不好，之前仅识别到人脸做一个大概的图片裁切，无法针对半身图，全身图进行。因此希望能够有方式能够识别到人体的关节，识别到人的肩膀， 腰部，腿部等等。</p>\n<p>我第一时间想到的是识别到人脸之后，获取到人脸宽高，再按比例去分割图片。例如我们常说九头身的模特身材，就是按人头大小去划分身体。第一个人脸高度为头部，第二个人脸高度为胸口，第三个人脸高度为腰部，这样类推。</p>\n<p>不过想到网上应该会有更加成熟的解决方案，所以去网上搜了一下，有一个叫 OpenPose 的开源项目能够很好的满足人体姿态识别的需求。</p>\n<h2 id=\"介绍\"><a class=\"markdownIt-Anchor\" href=\"#介绍\"></a> 介绍</h2>\n<p>OpenPose人体姿态识别项目是美国卡耐基梅隆大学（CMU）基于卷积神经网络和监督学习并以caffe为框架开发的开源库。可以实现人体动作、面部表情、手指运动等姿态估计。适用于单人和多人，具有极好的鲁棒性。是世界上首个基于深度学习的实时多人二维姿态估计应用，基于它的实例如雨后春笋般涌现。人体姿态估计技术在体育健身、动作采集、3D试衣、舆情监测等领域具有广阔的应用前景。</p>\n<p>Github地址： <a href=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose\">https://github.com/CMU-Perceptual-Computing-Lab/openpose</a></p>\n<p>这个项目有新手提供了很大的便利，在 Github Install档中有提供 Windows 安装的版本，或者仅需运行  OpenPose Demo即可（<a href=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/01_demo.md\">openpose/doc/01_demo.md</a>），该 Demo 提供了处理图片、视频或者网络摄像头的视频流，并展示和后处理结果。</p>\n<p>在 OpenPose 中，输入是一个或多个人的图像或视频，在这些图像中，OpenPose 会检测每个人的所有身体部位，并生成一个基于骨架的表示。OpenPose 使用两个深度卷积神经网络来实现此目的:Part Confidence Maps(PCM)和 Part Affinity Fields(PAFs)。PCM 预测每个像素属于人体部件的概率。PAFs则用于预测不同人体部位之间的连接情况。这两个网络都是基于ResNet架构的变形版本。一旦完成了所有部位的识别，OpenPose 将这些部位连接成一个完整的人体骨架，最终呈现出一个基于骨架的表示，呈现出每个人的不同身体部位和位置。</p>\n<p>OpenPose 的应用非常广泛，例如自动化驾驶、娱乐、运动分析、医疗等领域，它在这些领域中都有着非常重要的应用。</p>\n<h2 id=\"使用\"><a class=\"markdownIt-Anchor\" href=\"#使用\"></a> 使用</h2>\n<h3 id=\"安装\"><a class=\"markdownIt-Anchor\" href=\"#安装\"></a> 安装</h3>\n<p>我们需要通过 Python 来使用 OpenPose 的 API，因此要有Python环境</p>\n<p>然后安装 OpenCV 库</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install opencv</span><br></pre></td></tr></table></figure>\n<h3 id=\"下载模型\"><a class=\"markdownIt-Anchor\" href=\"#下载模型\"></a> 下载模型</h3>\n<p>一般我们要加载OpenPose的本地模型来进行识别</p>\n<p>模型分为 TensorFlow 模型（.pb 文件）和 Caffe 模型</p>\n<p>TensorFlow 模型我没有找到下载和转换的方式，各位如果了解的可以补充一下</p>\n<p>Caffe 模型需要拉取 Github 项目下来，在 Models 目录下执行 <code>getModels.bat</code>  或者  <code>getModels.sh</code> 来进行下载</p>\n<p>caffemodel 文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd models</span><br><span class=\"line\">.\\getModels.bat </span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">或者</span> </span><br><span class=\"line\">./getModels.sh</span><br></pre></td></tr></table></figure>\n<p>或者可以直接在网上搜索别人分享的文件，下载完成之后将模型中的 caffemodel  文件和 prototxt 文件一起放到自己项目目录中。</p>\n<p>其中官方项目中的 models 目录下面 pose 文件夹，又分为 body_25、coco、MPI。</p>\n<p>其中</p>\n<p><code>body_25</code>模型：这个模型是基于COCO数据集进行训练的，其中包含了25个关键点，可以检测出人体的各种姿势，如手臂、腿、头部等。它的训练数据集较大，适用于多种不同场景下的人体姿势估计任务。<code>pose_iter_584000.caffemodel</code>是该模型的网络权重文件。</p>\n<p><code>coco</code>模型：这个模型同样是基于COCO数据集进行训练的，但只包含了18个关键点，相对于<code>body_25</code>模型来说更简化了姿势表示。它的训练数据集中的标注数据是以COCO关键点标注为基础。<code>pose_iter_440000.caffemodel</code>是该模型的网络权重文件。</p>\n<p><code>mpi</code>模型：是基于 MPII 数据集进行训练的，该数据集包含了约 40,000 张单人姿势估计图像，检测出 15 个关键点，涵盖头部、躯干、手臂和腿部等主要部位。相对于COCO和body_25模型，MPI模型提供了更为简化的关键点表示。</p>\n<p>我这边使用的是 COCO 模型，因此复制 COCO 目录下的 <code>pose_deploy_linevec.prototxt</code> 文件以及下载好的 <code> pose_iter_440000.caffemodel</code> 到项目目录中使用即可</p>\n<h3 id=\"示例代码\"><a class=\"markdownIt-Anchor\" href=\"#示例代码\"></a> 示例代码</h3>\n<p>下面是一个示例代码，展示了如何使用 OpenPose 在 Python 中使用摄像头或视频文件获取图像实现多人姿态检测。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"></span><br><span class=\"line\">parser = argparse.ArgumentParser()</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">&quot;--video&quot;</span>, <span class=\"built_in\">help</span>=<span class=\"string\">&quot;path to video file. If empty, camera&#x27;s stream will be used&quot;</span>)</span><br><span class=\"line\">args = parser.parse_args()</span><br><span class=\"line\"></span><br><span class=\"line\">cap = cv2.VideoCapture(args.video <span class=\"keyword\">if</span> args.video <span class=\"keyword\">else</span> <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 导入 OpenPose 模型</span></span><br><span class=\"line\"><span class=\"comment\">#net = cv2.dnn.readNetFromTensorflow(&quot;models/pose/graph_opt.pb&quot;)</span></span><br><span class=\"line\">cv2.dnn.readNetFromCaffe(<span class=\"string\">&quot;data//pose/coco/pose_deploy_linevec.prototxt&quot;</span>,</span><br><span class=\"line\">                         <span class=\"string\">&quot;data/pose/coco/pose_iter_440000.caffemodel&quot;</span>) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># 从视频流中读取帧</span></span><br><span class=\"line\">    ret, frame = cap.read()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 帧处理</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ret:</span><br><span class=\"line\">        <span class=\"comment\"># 将帧转换为 Blob</span></span><br><span class=\"line\">        blob = cv2.dnn.blobFromImage(frame, <span class=\"number\">1.0</span> / <span class=\"number\">255</span>, (<span class=\"number\">368</span>, <span class=\"number\">368</span>), (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), swapRB=<span class=\"literal\">False</span>, crop=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        net.setInput(blob)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 运行前向传递</span></span><br><span class=\"line\">        out = net.forward()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 处理输出</span></span><br><span class=\"line\">        h, w, c = frame.shape</span><br><span class=\"line\">        points = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">18</span>):</span><br><span class=\"line\">            <span class=\"comment\"># 获取每个人体部位的可信度映射（PCM）</span></span><br><span class=\"line\">            heatMap = out[<span class=\"number\">0</span>, i, :, :]</span><br><span class=\"line\">            _, conf, _, point = cv2.minMaxLoc(heatMap)</span><br><span class=\"line\">            x = <span class=\"built_in\">int</span>(w * point[<span class=\"number\">0</span>] / out.shape[<span class=\"number\">3</span>])</span><br><span class=\"line\">            y = <span class=\"built_in\">int</span>(h * point[<span class=\"number\">1</span>] / out.shape[<span class=\"number\">2</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 将部位添加到列表中</span></span><br><span class=\"line\">            points.append((x, y) <span class=\"keyword\">if</span> conf &gt; <span class=\"number\">0.1</span> <span class=\"keyword\">else</span> <span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> pair <span class=\"keyword\">in</span> POSE_PAIRS:</span><br><span class=\"line\">            partFrom = pair[<span class=\"number\">0</span>]</span><br><span class=\"line\">            partTo = pair[<span class=\"number\">1</span>]</span><br><span class=\"line\">            idFrom = BODY_PARTS_DICT[partFrom]</span><br><span class=\"line\">            idTo = BODY_PARTS_DICT[partTo]</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> points[idFrom] <span class=\"keyword\">and</span> points[idTo]:</span><br><span class=\"line\">                <span class=\"comment\"># 绘制连线</span></span><br><span class=\"line\">                cv2.line(frame, points[idFrom], points[idTo], (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\">                cv2.circle(frame, points[idFrom], <span class=\"number\">5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), thickness=-<span class=\"number\">1</span>, lineType=cv2.FILLED)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 显示结果</span></span><br><span class=\"line\">        cv2.imshow(<span class=\"string\">&quot;Output-Keypoints&quot;</span>, frame)</span><br><span class=\"line\">        key = cv2.waitKey(<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> key == <span class=\"number\">27</span>:</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>\n<h2 id=\"单人物人体姿态识别\"><a class=\"markdownIt-Anchor\" href=\"#单人物人体姿态识别\"></a> 单人物人体姿态识别</h2>\n<p>我在这里实现了一个单人梯姿态识别代码，并且返回上下左右最顶端的坐标数组。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加载模型和配置文件</span></span><br><span class=\"line\">models = [<span class=\"string\">&#x27;models/pose/coco/pose_deploy_linevec.prototxt&#x27;</span>, <span class=\"string\">&#x27;models/pose/coco/pose_iter_440000.caffemodel&#x27;</span>]</span><br><span class=\"line\">net = cv2.dnn.readNetFromCaffe(*models)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义人体各部位的名称、颜色、连接关系和顺序</span></span><br><span class=\"line\">body_parts = &#123;<span class=\"string\">&#x27;Nose&#x27;</span>: <span class=\"number\">0</span>, <span class=\"string\">&#x27;Neck&#x27;</span>: <span class=\"number\">1</span>, <span class=\"string\">&#x27;RShoulder&#x27;</span>: <span class=\"number\">2</span>, <span class=\"string\">&#x27;RElbow&#x27;</span>: <span class=\"number\">3</span>, <span class=\"string\">&#x27;RWrist&#x27;</span>: <span class=\"number\">4</span>, <span class=\"string\">&#x27;LShoulder&#x27;</span>: <span class=\"number\">5</span>,</span><br><span class=\"line\">              <span class=\"string\">&#x27;LElbow&#x27;</span>: <span class=\"number\">6</span>, <span class=\"string\">&#x27;LWrist&#x27;</span>: <span class=\"number\">7</span>, <span class=\"string\">&#x27;RHip&#x27;</span>: <span class=\"number\">8</span>, <span class=\"string\">&#x27;RKnee&#x27;</span>: <span class=\"number\">9</span>, <span class=\"string\">&#x27;RAnkle&#x27;</span>: <span class=\"number\">10</span>, <span class=\"string\">&#x27;LHip&#x27;</span>: <span class=\"number\">11</span>,</span><br><span class=\"line\">              <span class=\"string\">&#x27;LKnee&#x27;</span>: <span class=\"number\">12</span>, <span class=\"string\">&#x27;LAnkle&#x27;</span>: <span class=\"number\">13</span>, <span class=\"string\">&#x27;REye&#x27;</span>: <span class=\"number\">14</span>, <span class=\"string\">&#x27;LEye&#x27;</span>: <span class=\"number\">15</span>, <span class=\"string\">&#x27;REar&#x27;</span>: <span class=\"number\">16</span>, <span class=\"string\">&#x27;LEar&#x27;</span>: <span class=\"number\">17</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">colors = [[<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>], [<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">100</span>, <span class=\"number\">50</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">          [<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>], [<span class=\"number\">100</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>], [<span class=\"number\">0</span>, <span class=\"number\">125</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">125</span>], [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">125</span>], [<span class=\"number\">125</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">          [<span class=\"number\">125</span>, <span class=\"number\">0</span>, <span class=\"number\">125</span>], [<span class=\"number\">125</span>, <span class=\"number\">125</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>], [<span class=\"number\">125</span>, <span class=\"number\">125</span>, <span class=\"number\">125</span>], [<span class=\"number\">50</span>, <span class=\"number\">100</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">100</span>, <span class=\"number\">50</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\">POSE_PAIRS = [[<span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;RShoulder&#x27;</span>], [<span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;LShoulder&#x27;</span>], [<span class=\"string\">&#x27;RShoulder&#x27;</span>, <span class=\"string\">&#x27;RElbow&#x27;</span>],</span><br><span class=\"line\">              [<span class=\"string\">&#x27;RElbow&#x27;</span>, <span class=\"string\">&#x27;RWrist&#x27;</span>], [<span class=\"string\">&#x27;LShoulder&#x27;</span>, <span class=\"string\">&#x27;LElbow&#x27;</span>], [<span class=\"string\">&#x27;LElbow&#x27;</span>, <span class=\"string\">&#x27;LWrist&#x27;</span>],</span><br><span class=\"line\">              [<span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;RHip&#x27;</span>], [<span class=\"string\">&#x27;RHip&#x27;</span>, <span class=\"string\">&#x27;RKnee&#x27;</span>], [<span class=\"string\">&#x27;RKnee&#x27;</span>, <span class=\"string\">&#x27;RAnkle&#x27;</span>], [<span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;LHip&#x27;</span>],</span><br><span class=\"line\">              [<span class=\"string\">&#x27;LHip&#x27;</span>, <span class=\"string\">&#x27;LKnee&#x27;</span>], [<span class=\"string\">&#x27;LKnee&#x27;</span>, <span class=\"string\">&#x27;LAnkle&#x27;</span>], [<span class=\"string\">&#x27;Nose&#x27;</span>, <span class=\"string\">&#x27;REye&#x27;</span>], [<span class=\"string\">&#x27;REye&#x27;</span>, <span class=\"string\">&#x27;REar&#x27;</span>],</span><br><span class=\"line\">              [<span class=\"string\">&#x27;Nose&#x27;</span>, <span class=\"string\">&#x27;LEye&#x27;</span>], [<span class=\"string\">&#x27;LEye&#x27;</span>, <span class=\"string\">&#x27;LEar&#x27;</span>], [<span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;Nose&#x27;</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">pose_detection</span>(<span class=\"params\">image, inWidth=<span class=\"number\">368</span>, inHeight=<span class=\"number\">368</span>, scale=<span class=\"number\">0.003922</span>, mean=(<span class=\"params\"><span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span></span>), swapRB=<span class=\"literal\">False</span>, crop=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    :param image: 输入的图像数据</span></span><br><span class=\"line\"><span class=\"string\">    :param inWidth: 输入图像的宽度，默认为368</span></span><br><span class=\"line\"><span class=\"string\">    :param inHeight: 输入图像的高度，默认为368</span></span><br><span class=\"line\"><span class=\"string\">    :param scale: 图像缩放因子，默认为0.003922</span></span><br><span class=\"line\"><span class=\"string\">    :param mean: 图像均值，默认为(0, 0, 0)</span></span><br><span class=\"line\"><span class=\"string\">    :param swapRB: 是否交换图像通道顺序，默认为False</span></span><br><span class=\"line\"><span class=\"string\">    :param crop: 是否进行裁剪，默认为False</span></span><br><span class=\"line\"><span class=\"string\">    :return: key_points：关键点坐标数组，get_vertex_coordinates(key_points)的结果：顶点坐标数组</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 读取输入的图像数据</span></span><br><span class=\"line\">    image = cv2.imread(img_path)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> image.shape[<span class=\"number\">0</span>] &gt; <span class=\"number\">800</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 如果图像的高度大于800，按比例缩放到高度为800</span></span><br><span class=\"line\">        image = cv2.resize(image, (<span class=\"built_in\">int</span>(image.shape[<span class=\"number\">1</span>] * <span class=\"number\">800</span> / image.shape[<span class=\"number\">0</span>]), <span class=\"number\">800</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 对输入图像进行预处理，生成blob对象</span></span><br><span class=\"line\">    blob = cv2.dnn.blobFromImage(image, scale, (inWidth, inHeight), mean, swapRB, crop)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 输入blob到神经网络中进行推断</span></span><br><span class=\"line\">    net.setInput(blob)</span><br><span class=\"line\">    <span class=\"comment\"># 获取输出结果</span></span><br><span class=\"line\">    output = net.forward()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 显示检测结果并添加关键点名称</span></span><br><span class=\"line\">    H = output.shape[<span class=\"number\">2</span>]</span><br><span class=\"line\">    W = output.shape[<span class=\"number\">3</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 初始化关键点坐标数组</span></span><br><span class=\"line\">    keypoints = [(<span class=\"number\">0</span>, <span class=\"number\">0</span>)] * <span class=\"built_in\">len</span>(body_parts)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 遍历输出结果，获取每个关键点的置信度和坐标</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, part_name <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(body_parts):</span><br><span class=\"line\">        confidenceMap = output[<span class=\"number\">0</span>, i, :, :]</span><br><span class=\"line\">        _, conf, _, point = cv2.minMaxLoc(confidenceMap)</span><br><span class=\"line\">        x = <span class=\"built_in\">int</span>((image.shape[<span class=\"number\">1</span>] * point[<span class=\"number\">0</span>]) / W)</span><br><span class=\"line\">        y = <span class=\"built_in\">int</span>((image.shape[<span class=\"number\">0</span>] * point[<span class=\"number\">1</span>]) / H)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> conf &gt; <span class=\"number\">0.1</span> <span class=\"keyword\">and</span> (x, y) != (<span class=\"number\">0</span>, <span class=\"number\">0</span>):</span><br><span class=\"line\">            <span class=\"built_in\">print</span>((x, y))</span><br><span class=\"line\">            <span class=\"comment\"># 将符合条件的关键点坐标保存到数组中</span></span><br><span class=\"line\">            keypoints[i] = (x, y)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 在图像上显示关键点</span></span><br><span class=\"line\">            cv2.circle(image, (x, y), <span class=\"number\">5</span>, (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>), -<span class=\"number\">1</span>)</span><br><span class=\"line\">            cv2.putText(image, <span class=\"string\">&quot;&#123;&#125;&quot;</span>.<span class=\"built_in\">format</span>(part_name), (x, y + <span class=\"number\">30</span>),</span><br><span class=\"line\">                        cv2.FONT_HERSHEY_SIMPLEX, <span class=\"number\">0.5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\">            cv2.putText(image, <span class=\"string\">&quot;(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(x, y), (x, y),</span><br><span class=\"line\">                        cv2.FONT_HERSHEY_SIMPLEX, <span class=\"number\">0.5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 将关键点两两相连并绘制到图像中</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> pair <span class=\"keyword\">in</span> POSE_PAIRS:</span><br><span class=\"line\">        part_a = pair[<span class=\"number\">0</span>]</span><br><span class=\"line\">        part_b = pair[<span class=\"number\">1</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> part_a <span class=\"keyword\">in</span> body_parts.keys() <span class=\"keyword\">and</span> part_b <span class=\"keyword\">in</span> body_parts.keys():</span><br><span class=\"line\">            id_a = body_parts[part_a]</span><br><span class=\"line\">            id_b = body_parts[part_b]</span><br><span class=\"line\">            <span class=\"keyword\">if</span> keypoints[id_a][<span class=\"number\">0</span>] != <span class=\"number\">0</span> <span class=\"keyword\">and</span> keypoints[id_a][<span class=\"number\">1</span>] != <span class=\"number\">0</span> <span class=\"keyword\">and</span> keypoints[id_b][<span class=\"number\">0</span>] != <span class=\"number\">0</span> <span class=\"keyword\">and</span> keypoints[id_b][</span><br><span class=\"line\">                <span class=\"number\">1</span>] != <span class=\"number\">0</span>:</span><br><span class=\"line\">                cv2.line(image, keypoints[id_a], keypoints[id_b], colors[id_a], <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 去除关键点数组中的无效点（坐标为(0, 0)）</span></span><br><span class=\"line\">    keypoints = [item <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> keypoints <span class=\"keyword\">if</span> item != (<span class=\"number\">0</span>, <span class=\"number\">0</span>)]</span><br><span class=\"line\">    <span class=\"comment\"># 将关键点数组转换为NumPy数组</span></span><br><span class=\"line\">    key_points = np.array(keypoints)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 显示处理后的图像</span></span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">&quot;output&quot;</span>, image)</span><br><span class=\"line\">    cv2.waitKey(<span class=\"number\">0</span>)</span><br><span class=\"line\">    cv2.destroyAllWindows()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 打印关键点数组的类型</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"built_in\">type</span>(key_points))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 返回关键点数组和顶点坐标数组</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> key_points, get_vertex_coordinates(key_points)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_vertex_coordinates</span>(<span class=\"params\">arr</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    获取坐标数组中的四个顶点坐标</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    :param arr: 包含坐标点的二维数组，行表示点的数量，列表示每个点的坐标轴数量</span></span><br><span class=\"line\"><span class=\"string\">    :return: arr 一个按照顺时针方向排列的四个顶点的坐标数组</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 找到最上、最下、最左、最右四个点的索引</span></span><br><span class=\"line\">    <span class=\"comment\"># 找到y轴坐标最小的点的索引</span></span><br><span class=\"line\">    top_idx = np.argmin(arr[:, <span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到y轴坐标最大的点的索引</span></span><br><span class=\"line\">    bottom_idx = np.argmax(arr[:, <span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到x轴坐标最小的点的索引</span></span><br><span class=\"line\">    left_idx = np.argmin(arr[:, <span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到x轴坐标最大的点的索引</span></span><br><span class=\"line\">    right_idx = np.argmax(arr[:, <span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 输出最上、最下、最左和最右四个点的坐标</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最上坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[top_idx][<span class=\"number\">0</span>], arr[top_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最下坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[bottom_idx][<span class=\"number\">0</span>], arr[bottom_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最左坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[left_idx][<span class=\"number\">0</span>], arr[left_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最右坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[right_idx][<span class=\"number\">0</span>], arr[right_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 按上右下左顺时针方向创建一个包含四个顶点坐标的数组</span></span><br><span class=\"line\">    coordinates = np.array([</span><br><span class=\"line\">        [arr[top_idx][<span class=\"number\">0</span>], arr[top_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[right_idx][<span class=\"number\">0</span>], arr[right_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[bottom_idx][<span class=\"number\">0</span>], arr[bottom_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[left_idx][<span class=\"number\">0</span>], arr[left_idx][<span class=\"number\">1</span>]]</span><br><span class=\"line\">    ])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> coordinates</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    <span class=\"comment\"># 读取输入图像</span></span><br><span class=\"line\">    img_path = <span class=\"string\">&#x27;img/img.png&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 进行人体姿态估计</span></span><br><span class=\"line\">    key_points, vertex_coordinates = pose_detection(image=img_path)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;关键点坐标：&#x27;</span>, key_points)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;四个顶点坐标：&#x27;</span>, vertex_coordinates)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>这个代码可以满足单个人物的姿态识别，并且能够获取到每个关节点的坐标，可以依据坐标进行裁剪图片，但是存在多个人物的时候，会出现识别有误，效果并不是很理想。</p>\n<h2 id=\"多人物人体姿态识别\"><a class=\"markdownIt-Anchor\" href=\"#多人物人体姿态识别\"></a> 多人物人体姿态识别</h2>\n<p>然后再找到了 <a href=\"https://learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/\">LearnOpenCV</a> 的一个多人姿态检测实现的文章（译文可见<a href=\"https://blog.csdn.net/qq_27158179/article/details/82717821\">基于OpenCV使用OpenPose进行多个人体姿态估计</a> ）。</p>\n<p>主要实现方式是识别多个人物的关键点（例如鼻子），再通过关键点查找有效连接点，例如某人鼻子的左肩通常为这个人的左肩，他右边识别到的左肩则应该为另外一个人的左肩。通过亲和性方向进行识别和连接然后组合就能识别出来不同人物的姿态组，再通过姿态组绘制骨骼图就得到最终我们想要的多人物姿态识别。感兴趣的朋友可以自行查阅原文。</p>\n<p>以下是我实际可用的代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br><span class=\"line\">355</span><br><span class=\"line\">356</span><br><span class=\"line\">357</span><br><span class=\"line\">358</span><br><span class=\"line\">359</span><br><span class=\"line\">360</span><br><span class=\"line\">361</span><br><span class=\"line\">362</span><br><span class=\"line\">363</span><br><span class=\"line\">364</span><br><span class=\"line\">365</span><br><span class=\"line\">366</span><br><span class=\"line\">367</span><br><span class=\"line\">368</span><br><span class=\"line\">369</span><br><span class=\"line\">370</span><br><span class=\"line\">371</span><br><span class=\"line\">372</span><br><span class=\"line\">373</span><br><span class=\"line\">374</span><br><span class=\"line\">375</span><br><span class=\"line\">376</span><br><span class=\"line\">377</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">该文件主要用于识别人体姿态并输出最边缘坐标</span></span><br><span class=\"line\"><span class=\"string\">主要函数为 detect_pose</span></span><br><span class=\"line\"><span class=\"string\">不需要预览结果请注释 cv2.imshow 等相关代码即可</span></span><br><span class=\"line\"><span class=\"string\">依赖库</span></span><br><span class=\"line\"><span class=\"string\">opencv-python~=4.7.0.72</span></span><br><span class=\"line\"><span class=\"string\">numpy~=1.24.2</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设定模型文件路径和关键点数量等信息</span></span><br><span class=\"line\"><span class=\"comment\"># 模型结构文件</span></span><br><span class=\"line\">protoFile = <span class=\"string\">&quot;data//pose/coco/pose_deploy_linevec.prototxt&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 训练好的参数文件</span></span><br><span class=\"line\">weightsFile = <span class=\"string\">&quot;data/pose/coco/pose_iter_440000.caffemodel&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># COCO 数据集中人体关键点的数量</span></span><br><span class=\"line\">nPoints = <span class=\"number\">18</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># COCO 数据集中的人体关键点名称列表</span></span><br><span class=\"line\">keypointsMapping = [<span class=\"string\">&#x27;Nose&#x27;</span>, <span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;R-Shoulder&#x27;</span>, <span class=\"string\">&#x27;R-Elbow&#x27;</span>, <span class=\"string\">&#x27;R-Wrist&#x27;</span>, <span class=\"string\">&#x27;L-Shoulder&#x27;</span>, <span class=\"string\">&#x27;L-Elbow&#x27;</span>, <span class=\"string\">&#x27;L-Wrist&#x27;</span>, <span class=\"string\">&#x27;R-Hip&#x27;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&#x27;R-Knee&#x27;</span>, <span class=\"string\">&#x27;R-Ankle&#x27;</span>, <span class=\"string\">&#x27;L-Hip&#x27;</span>, <span class=\"string\">&#x27;L-Knee&#x27;</span>, <span class=\"string\">&#x27;L-Ankle&#x27;</span>, <span class=\"string\">&#x27;R-Eye&#x27;</span>, <span class=\"string\">&#x27;L-Eye&#x27;</span>, <span class=\"string\">&#x27;R-Ear&#x27;</span>, <span class=\"string\">&#x27;L-Ear&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义连接不同关键点之间的线段，即人体的姿势</span></span><br><span class=\"line\"><span class=\"comment\"># 在 COCO 输出格式中，关键点的编号从 0 开始，即第 0 个点表示 Nose，最后一个点是 L-Ear</span></span><br><span class=\"line\">POSE_PAIRS = [[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">1</span>, <span class=\"number\">5</span>], [<span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>], [<span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">6</span>, <span class=\"number\">7</span>],</span><br><span class=\"line\">              [<span class=\"number\">1</span>, <span class=\"number\">8</span>], [<span class=\"number\">8</span>, <span class=\"number\">9</span>], [<span class=\"number\">9</span>, <span class=\"number\">10</span>], [<span class=\"number\">1</span>, <span class=\"number\">11</span>], [<span class=\"number\">11</span>, <span class=\"number\">12</span>], [<span class=\"number\">12</span>, <span class=\"number\">13</span>],</span><br><span class=\"line\">              [<span class=\"number\">1</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">14</span>], [<span class=\"number\">14</span>, <span class=\"number\">16</span>], [<span class=\"number\">0</span>, <span class=\"number\">15</span>], [<span class=\"number\">15</span>, <span class=\"number\">17</span>],</span><br><span class=\"line\">              [<span class=\"number\">2</span>, <span class=\"number\">17</span>], [<span class=\"number\">5</span>, <span class=\"number\">16</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义每个 POSE_PAIRS 对应的 PAF 在输出中的索引</span></span><br><span class=\"line\"><span class=\"comment\"># pafs与POSE_PAIRS的索引，例如，对于POSE_PAIR（1,2），PAF位于输出的指数（31,32），类似，（1,5）-&gt;（39,40）等。</span></span><br><span class=\"line\"><span class=\"comment\"># PAF 表示 Part Affinity Fields，即用于描述关键点之间连接情况的向量场</span></span><br><span class=\"line\"><span class=\"comment\"># 在这里，使用了 COCO 数据集中提供的预训练模型，其输出结果包括关键点坐标和 PAF</span></span><br><span class=\"line\">mapIdx = [[<span class=\"number\">31</span>, <span class=\"number\">32</span>], [<span class=\"number\">39</span>, <span class=\"number\">40</span>], [<span class=\"number\">33</span>, <span class=\"number\">34</span>], [<span class=\"number\">35</span>, <span class=\"number\">36</span>], [<span class=\"number\">41</span>, <span class=\"number\">42</span>], [<span class=\"number\">43</span>, <span class=\"number\">44</span>],</span><br><span class=\"line\">          [<span class=\"number\">19</span>, <span class=\"number\">20</span>], [<span class=\"number\">21</span>, <span class=\"number\">22</span>], [<span class=\"number\">23</span>, <span class=\"number\">24</span>], [<span class=\"number\">25</span>, <span class=\"number\">26</span>], [<span class=\"number\">27</span>, <span class=\"number\">28</span>], [<span class=\"number\">29</span>, <span class=\"number\">30</span>],</span><br><span class=\"line\">          [<span class=\"number\">47</span>, <span class=\"number\">48</span>], [<span class=\"number\">49</span>, <span class=\"number\">50</span>], [<span class=\"number\">53</span>, <span class=\"number\">54</span>], [<span class=\"number\">51</span>, <span class=\"number\">52</span>], [<span class=\"number\">55</span>, <span class=\"number\">56</span>],</span><br><span class=\"line\">          [<span class=\"number\">37</span>, <span class=\"number\">38</span>], [<span class=\"number\">45</span>, <span class=\"number\">46</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># # 定义用于绘制不同连接线段的颜色，根据定义的姿势连接线段，每个连接线段对应一种颜色</span></span><br><span class=\"line\">colors = [[<span class=\"number\">0</span>, <span class=\"number\">100</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">100</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">100</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">100</span>, <span class=\"number\">255</span>],</span><br><span class=\"line\">          [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>], [<span class=\"number\">255</span>, <span class=\"number\">200</span>, <span class=\"number\">100</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>], [<span class=\"number\">255</span>, <span class=\"number\">200</span>, <span class=\"number\">100</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>],</span><br><span class=\"line\">          [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">200</span>, <span class=\"number\">200</span>, <span class=\"number\">0</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">200</span>, <span class=\"number\">200</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 存储检测出来的所有关键点坐标列表，用于后续计算顶点</span></span><br><span class=\"line\">points = []</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">detect_pose</span>(<span class=\"params\">image_path</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    检测姿势</span></span><br><span class=\"line\"><span class=\"string\">    :param image_path: 图片路径</span></span><br><span class=\"line\"><span class=\"string\">    :return: 返回 pose, points</span></span><br><span class=\"line\"><span class=\"string\">    其中 pose 为</span></span><br><span class=\"line\"><span class=\"string\">    points 为 按照顺时针方向排列（即上右下左）的四个最顶点的坐标数组</span></span><br><span class=\"line\"><span class=\"string\">    调用函数例子如下：</span></span><br><span class=\"line\"><span class=\"string\">    path = &quot;img/test.png&quot;</span></span><br><span class=\"line\"><span class=\"string\">    pose, points = detect_pose(path)</span></span><br><span class=\"line\"><span class=\"string\">    print(points)</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 创建一个解析器</span></span><br><span class=\"line\">    parser = argparse.ArgumentParser(description=<span class=\"string\">&#x27;运行关键点检测&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 添加参数</span></span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">&quot;--device&quot;</span>, default=<span class=\"string\">&quot;cpu&quot;</span>, <span class=\"built_in\">help</span>=<span class=\"string\">&quot;推理设备&quot;</span>)</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">&quot;--image_file&quot;</span>, default=image_path, <span class=\"built_in\">help</span>=<span class=\"string\">&quot;输入图像&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析参数</span></span><br><span class=\"line\">    args = parser.parse_args()</span><br><span class=\"line\">    <span class=\"comment\"># 读取输入图像</span></span><br><span class=\"line\">    image1 = cv2.imread(args.image_file)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">getKeypoints</span>(<span class=\"params\">probMap, threshold=<span class=\"number\">0.1</span></span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        从输入的概率图（即 probMap）中提取关键点信息</span></span><br><span class=\"line\"><span class=\"string\">        :param probMap:  概率图</span></span><br><span class=\"line\"><span class=\"string\">        :param threshold: 二值化概率图时所采用的阈值，默认为 0.1</span></span><br><span class=\"line\"><span class=\"string\">        值较小时，可以提取出更多的关键点，但可能会包含一些噪声或冗余信息</span></span><br><span class=\"line\"><span class=\"string\">        值较大时，可以减少关键点的数量，但可能会漏掉一些有用信息</span></span><br><span class=\"line\"><span class=\"string\">        :return: 关键点列表</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"comment\"># 对概率图进行高斯模糊，以去除噪声。</span></span><br><span class=\"line\">        mapSmooth = cv2.GaussianBlur(probMap, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), <span class=\"number\">0</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 二值化概率图，生成一个二值掩模</span></span><br><span class=\"line\">        mapMask = np.uint8(mapSmooth &gt; threshold)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 寻找轮廓</span></span><br><span class=\"line\">        contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class=\"line\"></span><br><span class=\"line\">        keypoints = []</span><br><span class=\"line\">        <span class=\"comment\"># 针对每个轮廓寻找最大值</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> cnt <span class=\"keyword\">in</span> contours:</span><br><span class=\"line\">            <span class=\"comment\"># 构造一个与原图大小一致的全黑图像</span></span><br><span class=\"line\">            blobMask = np.zeros(mapMask.shape)</span><br><span class=\"line\">            <span class=\"comment\"># 在全黑图像上填充轮廓，轮廓内部的像素值为 1，其余像素值为 0</span></span><br><span class=\"line\">            blobMask = cv2.fillConvexPoly(blobMask, cnt, <span class=\"number\">1</span>)</span><br><span class=\"line\">            <span class=\"comment\"># 计算概率图中对应区域的最大值和坐标， 将概率图与二值图像相乘，得到关键点所在区域的图像</span></span><br><span class=\"line\">            maskedProbMap = mapSmooth * blobMask</span><br><span class=\"line\">            <span class=\"comment\"># 在关键点所在区域的图像中，寻找最大值及其坐标，即关键点的位置</span></span><br><span class=\"line\">            _, maxVal, _, maxLoc = cv2.minMaxLoc(maskedProbMap)</span><br><span class=\"line\">            <span class=\"comment\"># 在关键点列表中加入当前关键点的坐标和对应概率</span></span><br><span class=\"line\">            keypoints.append(maxLoc + (probMap[maxLoc[<span class=\"number\">1</span>], maxLoc[<span class=\"number\">0</span>]],))</span><br><span class=\"line\">            <span class=\"comment\"># 冗余存储各关键点坐标，用于下面计算顶点坐标</span></span><br><span class=\"line\">            points.append(maxLoc)</span><br><span class=\"line\">        <span class=\"comment\"># 返回关键点列表</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> keypoints</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">getValidPairs</span>(<span class=\"params\">output</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        在所有检测到的人中，寻找有效连接关系</span></span><br><span class=\"line\"><span class=\"string\">        :param output: 检测到的人体内容</span></span><br><span class=\"line\"><span class=\"string\">        :return: 有效连接关系列表，无效连接关系列表</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"comment\"># 存储有效连接关系</span></span><br><span class=\"line\">        valid_pairs = []</span><br><span class=\"line\">        <span class=\"comment\"># 存储无效连接关系</span></span><br><span class=\"line\">        invalid_pairs = []</span><br><span class=\"line\">        <span class=\"comment\"># 插值采样点数目</span></span><br><span class=\"line\">        n_interp_samples = <span class=\"number\">10</span></span><br><span class=\"line\">        <span class=\"comment\"># PAF 对齐阈值</span></span><br><span class=\"line\">        paf_score_th = <span class=\"number\">0.1</span></span><br><span class=\"line\">        <span class=\"comment\"># 有效连接容忍度阈值</span></span><br><span class=\"line\">        conf_th = <span class=\"number\">0.7</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 对于每个 POSE_PAIR 进行如下处理</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(mapIdx)):</span><br><span class=\"line\">            <span class=\"comment\"># 获取该连线关系相关联的两个 PAF</span></span><br><span class=\"line\">            pafA = output[<span class=\"number\">0</span>, mapIdx[k][<span class=\"number\">0</span>], :, :]</span><br><span class=\"line\">            pafB = output[<span class=\"number\">0</span>, mapIdx[k][<span class=\"number\">1</span>], :, :]</span><br><span class=\"line\">            <span class=\"comment\"># 调整 PAF 的大小为原始图像的大小</span></span><br><span class=\"line\">            pafA = cv2.resize(pafA, (frameWidth, frameHeight))</span><br><span class=\"line\">            pafB = cv2.resize(pafB, (frameWidth, frameHeight))</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 获取第一条连线关系和第二条连线关系的关键点</span></span><br><span class=\"line\">            candA = detected_keypoints[POSE_PAIRS[k][<span class=\"number\">0</span>]]</span><br><span class=\"line\">            candB = detected_keypoints[POSE_PAIRS[k][<span class=\"number\">1</span>]]</span><br><span class=\"line\">            <span class=\"comment\"># 连线关系的关键点数目</span></span><br><span class=\"line\">            nA = <span class=\"built_in\">len</span>(candA)</span><br><span class=\"line\">            nB = <span class=\"built_in\">len</span>(candB)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 如果检测到了该连线关系的关键点，遍历所有关键点，计算距离向量并进行插值</span></span><br><span class=\"line\">            <span class=\"comment\"># 最后根据公式计算连接得分，并判断连接是否有效</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (nA != <span class=\"number\">0</span> <span class=\"keyword\">and</span> nB != <span class=\"number\">0</span>):</span><br><span class=\"line\">                valid_pair = np.zeros((<span class=\"number\">0</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\">                <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(nA):</span><br><span class=\"line\">                    max_j = -<span class=\"number\">1</span></span><br><span class=\"line\">                    maxScore = -<span class=\"number\">1</span></span><br><span class=\"line\">                    found = <span class=\"number\">0</span></span><br><span class=\"line\">                    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(nB):</span><br><span class=\"line\">                        <span class=\"comment\"># 计算两个关键点之间的向量 d_ij</span></span><br><span class=\"line\">                        d_ij = np.subtract(candB[j][:<span class=\"number\">2</span>], candA[i][:<span class=\"number\">2</span>])</span><br><span class=\"line\">                        <span class=\"comment\"># 计算 d_ij 的模长</span></span><br><span class=\"line\">                        norm = np.linalg.norm(d_ij)</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> norm:</span><br><span class=\"line\">                            <span class=\"comment\"># 归一化处理</span></span><br><span class=\"line\">                            d_ij = d_ij / norm</span><br><span class=\"line\">                        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                            <span class=\"keyword\">continue</span></span><br><span class=\"line\">                        <span class=\"comment\"># # 对连接中介进行插值，生成 n_interp_samples 个采样点  p(u)</span></span><br><span class=\"line\">                        interp_coord = <span class=\"built_in\">list</span>(<span class=\"built_in\">zip</span>(np.linspace(candA[i][<span class=\"number\">0</span>], candB[j][<span class=\"number\">0</span>], num=n_interp_samples),</span><br><span class=\"line\">                                                np.linspace(candA[i][<span class=\"number\">1</span>], candB[j][<span class=\"number\">1</span>], num=n_interp_samples)))</span><br><span class=\"line\">                        <span class=\"comment\"># # 查询 PAF 值 L(p(u))</span></span><br><span class=\"line\">                        paf_interp = []</span><br><span class=\"line\">                        <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(interp_coord)):</span><br><span class=\"line\">                            paf_interp.append([pafA[<span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(interp_coord[k][<span class=\"number\">1</span>])), <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(interp_coord[k][<span class=\"number\">0</span>]))],</span><br><span class=\"line\">                                               pafB[<span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(interp_coord[k][<span class=\"number\">1</span>])), <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(interp_coord[k][<span class=\"number\">0</span>]))]])</span><br><span class=\"line\">                        <span class=\"comment\"># 计算连接得分 E</span></span><br><span class=\"line\">                        paf_scores = np.dot(paf_interp, d_ij)</span><br><span class=\"line\">                        avg_paf_score = <span class=\"built_in\">sum</span>(paf_scores) / <span class=\"built_in\">len</span>(paf_scores)</span><br><span class=\"line\"></span><br><span class=\"line\">                        <span class=\"comment\"># 如果插值采样点中对齐 PAF 向量的比例高于阈值，则判定为有效连接关系</span></span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (<span class=\"built_in\">len</span>(np.where(paf_scores &gt; paf_score_th)[<span class=\"number\">0</span>]) / n_interp_samples) &gt; conf_th:</span><br><span class=\"line\">                            <span class=\"keyword\">if</span> avg_paf_score &gt; maxScore:</span><br><span class=\"line\">                                max_j = j</span><br><span class=\"line\">                                maxScore = avg_paf_score</span><br><span class=\"line\">                                found = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">                    <span class=\"comment\"># 将有效连接信息添加到列表中</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> found:</span><br><span class=\"line\">                        valid_pair = np.append(valid_pair, [[candA[i][<span class=\"number\">3</span>], candB[max_j][<span class=\"number\">3</span>], maxScore]], axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"comment\"># 将有效连接信息存入全局列表中</span></span><br><span class=\"line\">                valid_pairs.append(valid_pair)</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"comment\"># 没有检测到关键点，说明连接无效</span></span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;没有连接 : k = &#123;&#125;&quot;</span>.<span class=\"built_in\">format</span>(k))</span><br><span class=\"line\">                invalid_pairs.append(k)</span><br><span class=\"line\">                valid_pairs.append([])</span><br><span class=\"line\">        <span class=\"comment\"># 返回有效连接关系列表和无效连接关系列表</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> valid_pairs, invalid_pairs</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">getPersonwiseKeypoints</span>(<span class=\"params\">valid_pairs, invalid_pairs</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        遍历所有有效连接关系，将其对应的关键点分配给不同的人，并计算出每个人在当前姿态下的得分。</span></span><br><span class=\"line\"><span class=\"string\">        这样可以更为合适地去描绘人体姿态，减少出现 A 的左眼连结到 B 的右眼的情况</span></span><br><span class=\"line\"><span class=\"string\">        :param valid_pairs:  有效连接关系列表</span></span><br><span class=\"line\"><span class=\"string\">        :param invalid_pairs: 无效连接关系列表</span></span><br><span class=\"line\"><span class=\"string\">        :return: 个性化关键点数组</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"comment\"># 每一行最后一个元素是总得分</span></span><br><span class=\"line\">        personwiseKeypoints = -<span class=\"number\">1</span> * np.ones((<span class=\"number\">0</span>, <span class=\"number\">19</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 遍历所有有效连接关系</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(mapIdx)):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> k <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> invalid_pairs:</span><br><span class=\"line\">                <span class=\"comment\"># partAs 和 partBs 分别是相互连接的两个关节点</span></span><br><span class=\"line\">                partAs = valid_pairs[k][:, <span class=\"number\">0</span>]</span><br><span class=\"line\">                partBs = valid_pairs[k][:, <span class=\"number\">1</span>]</span><br><span class=\"line\">                indexA, indexB = np.array(POSE_PAIRS[k])</span><br><span class=\"line\">                <span class=\"comment\"># 将 B 的分数加到 A 所在行的总得分中，或创建一个新行</span></span><br><span class=\"line\">                <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(valid_pairs[k])):</span><br><span class=\"line\">                    found = <span class=\"number\">0</span></span><br><span class=\"line\">                    person_idx = -<span class=\"number\">1</span></span><br><span class=\"line\">                    <span class=\"comment\"># 在已有的姿态中查找 partA。</span></span><br><span class=\"line\">                    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(personwiseKeypoints)):</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> personwiseKeypoints[j][indexA] == partAs[i]:</span><br><span class=\"line\">                            person_idx = j</span><br><span class=\"line\">                            found = <span class=\"number\">1</span></span><br><span class=\"line\">                            <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">                    <span class=\"comment\"># 如果在当前姿态中找到了与 partA 相关联的关键点，则将 partB 添加到该行。</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> found:</span><br><span class=\"line\">                        personwiseKeypoints[person_idx][indexB] = partBs[i]</span><br><span class=\"line\">                        <span class=\"comment\"># 在该姿态下，添加 partB 的关键点分数以及连接得分到该行的总得分中。</span></span><br><span class=\"line\">                        personwiseKeypoints[person_idx][-<span class=\"number\">1</span>] += keypoints_list[partBs[i].astype(<span class=\"built_in\">int</span>), <span class=\"number\">2</span>] + \\</span><br><span class=\"line\">                                                               valid_pairs[k][i][</span><br><span class=\"line\">                                                                   <span class=\"number\">2</span>]</span><br><span class=\"line\">                    <span class=\"comment\"># 如果当前姿态中不存在与 partA 相关联的关键点，则创建一个新姿态</span></span><br><span class=\"line\">                    <span class=\"keyword\">elif</span> <span class=\"keyword\">not</span> found <span class=\"keyword\">and</span> k &lt; <span class=\"number\">17</span>:</span><br><span class=\"line\">                        row = -<span class=\"number\">1</span> * np.ones(<span class=\"number\">19</span>)</span><br><span class=\"line\">                        row[indexA] = partAs[i]</span><br><span class=\"line\">                        row[indexB] = partBs[i]</span><br><span class=\"line\">                        <span class=\"comment\"># 在该姿态下，将两个关键点的关键点分数 scores 以及连接得分加起来作为该行的总得分。</span></span><br><span class=\"line\">                        row[-<span class=\"number\">1</span>] = <span class=\"built_in\">sum</span>(keypoints_list[valid_pairs[k][i, :<span class=\"number\">2</span>].astype(<span class=\"built_in\">int</span>), <span class=\"number\">2</span>]) + valid_pairs[k][i][<span class=\"number\">2</span>]</span><br><span class=\"line\">                        personwiseKeypoints = np.vstack([personwiseKeypoints, row])</span><br><span class=\"line\">        <span class=\"comment\"># 最终返回一个二维数组，每行代表一个人体姿态，每列代表一个关节点。</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> personwiseKeypoints</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 获取图像的宽度和高度</span></span><br><span class=\"line\">    frameWidth = image1.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    frameHeight = image1.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    t = time.time()</span><br><span class=\"line\">    <span class=\"comment\"># 从磁盘上读取预训练模型</span></span><br><span class=\"line\">    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)</span><br><span class=\"line\">    <span class=\"comment\"># 指定运行模型的设备类型，如果使用CPU则设置为CPU，否则设置为GPU</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> args.device == <span class=\"string\">&quot;cpu&quot;</span>:</span><br><span class=\"line\">        net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;使用 CPU&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> args.device == <span class=\"string\">&quot;gpu&quot;</span>:</span><br><span class=\"line\">        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)</span><br><span class=\"line\">        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;使用 GPU&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 固定输入图像的高度，并根据图像的宽高比来计算输入的宽度</span></span><br><span class=\"line\">    inHeight = <span class=\"number\">368</span></span><br><span class=\"line\">    inWidth = <span class=\"built_in\">int</span>((inHeight / frameHeight) * frameWidth)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 将输入图像转换为Blob格式，并进行归一化和缩放</span></span><br><span class=\"line\">    inpBlob = cv2.dnn.blobFromImage(image1, <span class=\"number\">1.0</span> / <span class=\"number\">255</span>, (inWidth, inHeight),</span><br><span class=\"line\">                                    (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), swapRB=<span class=\"literal\">False</span>, crop=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 将输入Blob传递给网络</span></span><br><span class=\"line\">    net.setInput(inpBlob)</span><br><span class=\"line\">    <span class=\"comment\"># 运行前馈传递，可以获取到识别的人脸</span></span><br><span class=\"line\">    output = net.forward()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;前馈传递所需时间 = &#123;&#125;&quot;</span>.<span class=\"built_in\">format</span>(time.time() - t))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 定义一个列表用于存储检测出的所有关键点</span></span><br><span class=\"line\">    detected_keypoints = []</span><br><span class=\"line\">    <span class=\"comment\"># 创建一个 shape 为 (0, 3) 的 numpy 数组，用于保存关键点的位置和 id</span></span><br><span class=\"line\">    keypoints_list = np.zeros((<span class=\"number\">0</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\">    <span class=\"comment\"># 初始化关键点 id</span></span><br><span class=\"line\">    keypoint_id = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"comment\"># 设置概率阈值</span></span><br><span class=\"line\">    threshold = <span class=\"number\">0.1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 遍历每个关键点</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> part <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(nPoints):</span><br><span class=\"line\">        <span class=\"comment\"># 获取关键点对应的概率图，并将其 resize 到与输入图像相同的大小</span></span><br><span class=\"line\">        probMap = output[<span class=\"number\">0</span>, part, :, :]</span><br><span class=\"line\">        probMap = cv2.resize(probMap, (image1.shape[<span class=\"number\">1</span>], image1.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 根据阈值获取该关键点的位置</span></span><br><span class=\"line\">        keypoints = getKeypoints(probMap, threshold)</span><br><span class=\"line\">        <span class=\"comment\"># 输出该关键点的位置信息</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Keypoints - &#123;&#125; : &#123;&#125;&quot;</span>.<span class=\"built_in\">format</span>(keypointsMapping[part], keypoints))</span><br><span class=\"line\">        <span class=\"comment\"># 存储关键点的位置和 id</span></span><br><span class=\"line\">        keypoints_with_id = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(keypoints)):</span><br><span class=\"line\">            keypoints_with_id.append(keypoints[i] + (keypoint_id,))</span><br><span class=\"line\">            keypoints_list = np.vstack([keypoints_list, keypoints[i]])</span><br><span class=\"line\">            keypoint_id += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">        detected_keypoints.append(keypoints_with_id)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 在原始图像上绘制所有检测出的关键点和 id</span></span><br><span class=\"line\">    frameClone = image1.copy()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(nPoints):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(detected_keypoints[i])):</span><br><span class=\"line\">            <span class=\"comment\"># 输出关键点对应的坐标和名称</span></span><br><span class=\"line\">            <span class=\"built_in\">print</span>(detected_keypoints[i][j][<span class=\"number\">0</span>:<span class=\"number\">2</span>])</span><br><span class=\"line\">            cv2.putText(frameClone, <span class=\"string\">&quot;&#123;&#125;&quot;</span>.<span class=\"built_in\">format</span>(keypointsMapping[i]), detected_keypoints[i][j][<span class=\"number\">0</span>:<span class=\"number\">2</span>],</span><br><span class=\"line\">                        cv2.FONT_HERSHEY_SIMPLEX, <span class=\"number\">0.5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\">            cv2.putText(frameClone, <span class=\"string\">&quot;(&#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(detected_keypoints[i][j]), detected_keypoints[i][j][<span class=\"number\">0</span>:<span class=\"number\">2</span>],</span><br><span class=\"line\">                        cv2.FONT_HERSHEY_SIMPLEX, <span class=\"number\">0.5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\">            cv2.circle(frameClone, detected_keypoints[i][j][<span class=\"number\">0</span>:<span class=\"number\">2</span>], <span class=\"number\">5</span>, colors[i], -<span class=\"number\">1</span>, cv2.LINE_AA)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 在原始图像上绘制每条相邻关键点之间的连线，描绘人体的姿态</span></span><br><span class=\"line\">    valid_pairs, invalid_pairs = getValidPairs(output)</span><br><span class=\"line\">    personwiseKeypoints = getPersonwiseKeypoints(valid_pairs, invalid_pairs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">17</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> n <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(personwiseKeypoints)):</span><br><span class=\"line\">            index = personwiseKeypoints[n][np.array(POSE_PAIRS[i])]</span><br><span class=\"line\">            <span class=\"keyword\">if</span> -<span class=\"number\">1</span> <span class=\"keyword\">in</span> index:</span><br><span class=\"line\">                <span class=\"keyword\">continue</span></span><br><span class=\"line\">            B = np.int32(keypoints_list[index.astype(<span class=\"built_in\">int</span>), <span class=\"number\">0</span>])</span><br><span class=\"line\">            A = np.int32(keypoints_list[index.astype(<span class=\"built_in\">int</span>), <span class=\"number\">1</span>])</span><br><span class=\"line\">            cv2.line(frameClone, (B[<span class=\"number\">0</span>], A[<span class=\"number\">0</span>]), (B[<span class=\"number\">1</span>], A[<span class=\"number\">1</span>]), colors[i], <span class=\"number\">3</span>, cv2.LINE_AA)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 可视化显示检测结果，仅供预览使用，这部分可注释</span></span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">&quot;关键点&quot;</span>, frameClone)</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">&quot;姿态检测&quot;</span>, frameClone)</span><br><span class=\"line\">    cv2.waitKey(<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 返回检测到的人体关键点和身体姿态的信息</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> personwiseKeypoints[<span class=\"number\">0</span>] <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(personwiseKeypoints) &gt; <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"literal\">None</span>, get_vertex_coordinates(points)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_vertex_coordinates</span>(<span class=\"params\">arr</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    获取坐标数组中的四个顶点坐标</span></span><br><span class=\"line\"><span class=\"string\">    :param arr: 包含坐标点的二维数组，行表示点的数量，列表示每个点的坐标轴数量</span></span><br><span class=\"line\"><span class=\"string\">    :return: arr 一个按照顺时针方向排列的四个顶点的坐标数组</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    arr = np.array(arr)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 找到最上、最下、最左、最右四个点的索引</span></span><br><span class=\"line\">    <span class=\"comment\"># 找到y轴坐标最小的点的索引</span></span><br><span class=\"line\">    top_idx = np.argmin(arr[:, <span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到y轴坐标最大的点的索引</span></span><br><span class=\"line\">    bottom_idx = np.argmax(arr[:, <span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到x轴坐标最小的点的索引</span></span><br><span class=\"line\">    left_idx = np.argmin(arr[:, <span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到x轴坐标最大的点的索引</span></span><br><span class=\"line\">    right_idx = np.argmax(arr[:, <span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 输出最上、最下、最左和最右四个点的坐标</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最上坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[top_idx][<span class=\"number\">0</span>], arr[top_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最下坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[bottom_idx][<span class=\"number\">0</span>], arr[bottom_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最左坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[left_idx][<span class=\"number\">0</span>], arr[left_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最右坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[right_idx][<span class=\"number\">0</span>], arr[right_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 按上右下左顺时针方向创建一个包含四个顶点坐标的数组</span></span><br><span class=\"line\">    coordinates = np.array([</span><br><span class=\"line\">        [arr[top_idx][<span class=\"number\">0</span>], arr[top_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[right_idx][<span class=\"number\">0</span>], arr[right_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[bottom_idx][<span class=\"number\">0</span>], arr[bottom_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[left_idx][<span class=\"number\">0</span>], arr[left_idx][<span class=\"number\">1</span>]]</span><br><span class=\"line\">    ])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> coordinates</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    path = <span class=\"string\">&quot;../data/result.png&quot;</span></span><br><span class=\"line\">    pose, points = detect_pose(path)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;------------&#x27;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(points)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>结果返回了多个关键点和四个方向顶点坐标数组，可以看到效果还是很好的，可以满足业务需求了。</p>\n<h2 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h2>\n<blockquote>\n<p><a href=\"https://www.jianshu.com/p/3aa810b35a5d\">Github开源人体姿态识别项目OpenPose中文文档 - 简书</a></p>\n<p><a href=\"https://blog.csdn.net/qq_27158179/article/details/82717821\">基于OpenCV使用OpenPose进行多个人体姿态估计_qq_27158179的CSDN博客</a></p>\n<p><a href=\"https://learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/\">Multi Person Pose Estimation in OpenCV using OpenPose (learnopencv.com)</a></p>\n</blockquote>\n","more":"<h2 id=\"背景\"><a class=\"markdownIt-Anchor\" href=\"#背景\"></a> 背景</h2>\n<p>合作公司有个小伙伴提到之前要处理图片中对人物裁剪的效果不好，之前仅识别到人脸做一个大概的图片裁切，无法针对半身图，全身图进行。因此希望能够有方式能够识别到人体的关节，识别到人的肩膀， 腰部，腿部等等。</p>\n<p>我第一时间想到的是识别到人脸之后，获取到人脸宽高，再按比例去分割图片。例如我们常说九头身的模特身材，就是按人头大小去划分身体。第一个人脸高度为头部，第二个人脸高度为胸口，第三个人脸高度为腰部，这样类推。</p>\n<p>不过想到网上应该会有更加成熟的解决方案，所以去网上搜了一下，有一个叫 OpenPose 的开源项目能够很好的满足人体姿态识别的需求。</p>\n<h2 id=\"介绍\"><a class=\"markdownIt-Anchor\" href=\"#介绍\"></a> 介绍</h2>\n<p>OpenPose人体姿态识别项目是美国卡耐基梅隆大学（CMU）基于卷积神经网络和监督学习并以caffe为框架开发的开源库。可以实现人体动作、面部表情、手指运动等姿态估计。适用于单人和多人，具有极好的鲁棒性。是世界上首个基于深度学习的实时多人二维姿态估计应用，基于它的实例如雨后春笋般涌现。人体姿态估计技术在体育健身、动作采集、3D试衣、舆情监测等领域具有广阔的应用前景。</p>\n<p>Github地址： <a href=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose\">https://github.com/CMU-Perceptual-Computing-Lab/openpose</a></p>\n<p>这个项目有新手提供了很大的便利，在 Github Install档中有提供 Windows 安装的版本，或者仅需运行  OpenPose Demo即可（<a href=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/01_demo.md\">openpose/doc/01_demo.md</a>），该 Demo 提供了处理图片、视频或者网络摄像头的视频流，并展示和后处理结果。</p>\n<p>在 OpenPose 中，输入是一个或多个人的图像或视频，在这些图像中，OpenPose 会检测每个人的所有身体部位，并生成一个基于骨架的表示。OpenPose 使用两个深度卷积神经网络来实现此目的:Part Confidence Maps(PCM)和 Part Affinity Fields(PAFs)。PCM 预测每个像素属于人体部件的概率。PAFs则用于预测不同人体部位之间的连接情况。这两个网络都是基于ResNet架构的变形版本。一旦完成了所有部位的识别，OpenPose 将这些部位连接成一个完整的人体骨架，最终呈现出一个基于骨架的表示，呈现出每个人的不同身体部位和位置。</p>\n<p>OpenPose 的应用非常广泛，例如自动化驾驶、娱乐、运动分析、医疗等领域，它在这些领域中都有着非常重要的应用。</p>\n<h2 id=\"使用\"><a class=\"markdownIt-Anchor\" href=\"#使用\"></a> 使用</h2>\n<h3 id=\"安装\"><a class=\"markdownIt-Anchor\" href=\"#安装\"></a> 安装</h3>\n<p>我们需要通过 Python 来使用 OpenPose 的 API，因此要有Python环境</p>\n<p>然后安装 OpenCV 库</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install opencv</span><br></pre></td></tr></table></figure>\n<h3 id=\"下载模型\"><a class=\"markdownIt-Anchor\" href=\"#下载模型\"></a> 下载模型</h3>\n<p>一般我们要加载OpenPose的本地模型来进行识别</p>\n<p>模型分为 TensorFlow 模型（.pb 文件）和 Caffe 模型</p>\n<p>TensorFlow 模型我没有找到下载和转换的方式，各位如果了解的可以补充一下</p>\n<p>Caffe 模型需要拉取 Github 项目下来，在 Models 目录下执行 <code>getModels.bat</code>  或者  <code>getModels.sh</code> 来进行下载</p>\n<p>caffemodel 文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd models</span><br><span class=\"line\">.\\getModels.bat </span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">或者</span> </span><br><span class=\"line\">./getModels.sh</span><br></pre></td></tr></table></figure>\n<p>或者可以直接在网上搜索别人分享的文件，下载完成之后将模型中的 caffemodel  文件和 prototxt 文件一起放到自己项目目录中。</p>\n<p>其中官方项目中的 models 目录下面 pose 文件夹，又分为 body_25、coco、MPI。</p>\n<p>其中</p>\n<p><code>body_25</code>模型：这个模型是基于COCO数据集进行训练的，其中包含了25个关键点，可以检测出人体的各种姿势，如手臂、腿、头部等。它的训练数据集较大，适用于多种不同场景下的人体姿势估计任务。<code>pose_iter_584000.caffemodel</code>是该模型的网络权重文件。</p>\n<p><code>coco</code>模型：这个模型同样是基于COCO数据集进行训练的，但只包含了18个关键点，相对于<code>body_25</code>模型来说更简化了姿势表示。它的训练数据集中的标注数据是以COCO关键点标注为基础。<code>pose_iter_440000.caffemodel</code>是该模型的网络权重文件。</p>\n<p><code>mpi</code>模型：是基于 MPII 数据集进行训练的，该数据集包含了约 40,000 张单人姿势估计图像，检测出 15 个关键点，涵盖头部、躯干、手臂和腿部等主要部位。相对于COCO和body_25模型，MPI模型提供了更为简化的关键点表示。</p>\n<p>我这边使用的是 COCO 模型，因此复制 COCO 目录下的 <code>pose_deploy_linevec.prototxt</code> 文件以及下载好的 <code> pose_iter_440000.caffemodel</code> 到项目目录中使用即可</p>\n<h3 id=\"示例代码\"><a class=\"markdownIt-Anchor\" href=\"#示例代码\"></a> 示例代码</h3>\n<p>下面是一个示例代码，展示了如何使用 OpenPose 在 Python 中使用摄像头或视频文件获取图像实现多人姿态检测。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"></span><br><span class=\"line\">parser = argparse.ArgumentParser()</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">&quot;--video&quot;</span>, <span class=\"built_in\">help</span>=<span class=\"string\">&quot;path to video file. If empty, camera&#x27;s stream will be used&quot;</span>)</span><br><span class=\"line\">args = parser.parse_args()</span><br><span class=\"line\"></span><br><span class=\"line\">cap = cv2.VideoCapture(args.video <span class=\"keyword\">if</span> args.video <span class=\"keyword\">else</span> <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 导入 OpenPose 模型</span></span><br><span class=\"line\"><span class=\"comment\">#net = cv2.dnn.readNetFromTensorflow(&quot;models/pose/graph_opt.pb&quot;)</span></span><br><span class=\"line\">cv2.dnn.readNetFromCaffe(<span class=\"string\">&quot;data//pose/coco/pose_deploy_linevec.prototxt&quot;</span>,</span><br><span class=\"line\">                         <span class=\"string\">&quot;data/pose/coco/pose_iter_440000.caffemodel&quot;</span>) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># 从视频流中读取帧</span></span><br><span class=\"line\">    ret, frame = cap.read()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 帧处理</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ret:</span><br><span class=\"line\">        <span class=\"comment\"># 将帧转换为 Blob</span></span><br><span class=\"line\">        blob = cv2.dnn.blobFromImage(frame, <span class=\"number\">1.0</span> / <span class=\"number\">255</span>, (<span class=\"number\">368</span>, <span class=\"number\">368</span>), (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), swapRB=<span class=\"literal\">False</span>, crop=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        net.setInput(blob)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 运行前向传递</span></span><br><span class=\"line\">        out = net.forward()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 处理输出</span></span><br><span class=\"line\">        h, w, c = frame.shape</span><br><span class=\"line\">        points = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">18</span>):</span><br><span class=\"line\">            <span class=\"comment\"># 获取每个人体部位的可信度映射（PCM）</span></span><br><span class=\"line\">            heatMap = out[<span class=\"number\">0</span>, i, :, :]</span><br><span class=\"line\">            _, conf, _, point = cv2.minMaxLoc(heatMap)</span><br><span class=\"line\">            x = <span class=\"built_in\">int</span>(w * point[<span class=\"number\">0</span>] / out.shape[<span class=\"number\">3</span>])</span><br><span class=\"line\">            y = <span class=\"built_in\">int</span>(h * point[<span class=\"number\">1</span>] / out.shape[<span class=\"number\">2</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 将部位添加到列表中</span></span><br><span class=\"line\">            points.append((x, y) <span class=\"keyword\">if</span> conf &gt; <span class=\"number\">0.1</span> <span class=\"keyword\">else</span> <span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> pair <span class=\"keyword\">in</span> POSE_PAIRS:</span><br><span class=\"line\">            partFrom = pair[<span class=\"number\">0</span>]</span><br><span class=\"line\">            partTo = pair[<span class=\"number\">1</span>]</span><br><span class=\"line\">            idFrom = BODY_PARTS_DICT[partFrom]</span><br><span class=\"line\">            idTo = BODY_PARTS_DICT[partTo]</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> points[idFrom] <span class=\"keyword\">and</span> points[idTo]:</span><br><span class=\"line\">                <span class=\"comment\"># 绘制连线</span></span><br><span class=\"line\">                cv2.line(frame, points[idFrom], points[idTo], (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\">                cv2.circle(frame, points[idFrom], <span class=\"number\">5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), thickness=-<span class=\"number\">1</span>, lineType=cv2.FILLED)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 显示结果</span></span><br><span class=\"line\">        cv2.imshow(<span class=\"string\">&quot;Output-Keypoints&quot;</span>, frame)</span><br><span class=\"line\">        key = cv2.waitKey(<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> key == <span class=\"number\">27</span>:</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>\n<h2 id=\"单人物人体姿态识别\"><a class=\"markdownIt-Anchor\" href=\"#单人物人体姿态识别\"></a> 单人物人体姿态识别</h2>\n<p>我在这里实现了一个单人梯姿态识别代码，并且返回上下左右最顶端的坐标数组。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加载模型和配置文件</span></span><br><span class=\"line\">models = [<span class=\"string\">&#x27;models/pose/coco/pose_deploy_linevec.prototxt&#x27;</span>, <span class=\"string\">&#x27;models/pose/coco/pose_iter_440000.caffemodel&#x27;</span>]</span><br><span class=\"line\">net = cv2.dnn.readNetFromCaffe(*models)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义人体各部位的名称、颜色、连接关系和顺序</span></span><br><span class=\"line\">body_parts = &#123;<span class=\"string\">&#x27;Nose&#x27;</span>: <span class=\"number\">0</span>, <span class=\"string\">&#x27;Neck&#x27;</span>: <span class=\"number\">1</span>, <span class=\"string\">&#x27;RShoulder&#x27;</span>: <span class=\"number\">2</span>, <span class=\"string\">&#x27;RElbow&#x27;</span>: <span class=\"number\">3</span>, <span class=\"string\">&#x27;RWrist&#x27;</span>: <span class=\"number\">4</span>, <span class=\"string\">&#x27;LShoulder&#x27;</span>: <span class=\"number\">5</span>,</span><br><span class=\"line\">              <span class=\"string\">&#x27;LElbow&#x27;</span>: <span class=\"number\">6</span>, <span class=\"string\">&#x27;LWrist&#x27;</span>: <span class=\"number\">7</span>, <span class=\"string\">&#x27;RHip&#x27;</span>: <span class=\"number\">8</span>, <span class=\"string\">&#x27;RKnee&#x27;</span>: <span class=\"number\">9</span>, <span class=\"string\">&#x27;RAnkle&#x27;</span>: <span class=\"number\">10</span>, <span class=\"string\">&#x27;LHip&#x27;</span>: <span class=\"number\">11</span>,</span><br><span class=\"line\">              <span class=\"string\">&#x27;LKnee&#x27;</span>: <span class=\"number\">12</span>, <span class=\"string\">&#x27;LAnkle&#x27;</span>: <span class=\"number\">13</span>, <span class=\"string\">&#x27;REye&#x27;</span>: <span class=\"number\">14</span>, <span class=\"string\">&#x27;LEye&#x27;</span>: <span class=\"number\">15</span>, <span class=\"string\">&#x27;REar&#x27;</span>: <span class=\"number\">16</span>, <span class=\"string\">&#x27;LEar&#x27;</span>: <span class=\"number\">17</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">colors = [[<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>], [<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">100</span>, <span class=\"number\">50</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">          [<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>], [<span class=\"number\">100</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>], [<span class=\"number\">0</span>, <span class=\"number\">125</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">125</span>], [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">125</span>], [<span class=\"number\">125</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">          [<span class=\"number\">125</span>, <span class=\"number\">0</span>, <span class=\"number\">125</span>], [<span class=\"number\">125</span>, <span class=\"number\">125</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>], [<span class=\"number\">125</span>, <span class=\"number\">125</span>, <span class=\"number\">125</span>], [<span class=\"number\">50</span>, <span class=\"number\">100</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">100</span>, <span class=\"number\">50</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\">POSE_PAIRS = [[<span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;RShoulder&#x27;</span>], [<span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;LShoulder&#x27;</span>], [<span class=\"string\">&#x27;RShoulder&#x27;</span>, <span class=\"string\">&#x27;RElbow&#x27;</span>],</span><br><span class=\"line\">              [<span class=\"string\">&#x27;RElbow&#x27;</span>, <span class=\"string\">&#x27;RWrist&#x27;</span>], [<span class=\"string\">&#x27;LShoulder&#x27;</span>, <span class=\"string\">&#x27;LElbow&#x27;</span>], [<span class=\"string\">&#x27;LElbow&#x27;</span>, <span class=\"string\">&#x27;LWrist&#x27;</span>],</span><br><span class=\"line\">              [<span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;RHip&#x27;</span>], [<span class=\"string\">&#x27;RHip&#x27;</span>, <span class=\"string\">&#x27;RKnee&#x27;</span>], [<span class=\"string\">&#x27;RKnee&#x27;</span>, <span class=\"string\">&#x27;RAnkle&#x27;</span>], [<span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;LHip&#x27;</span>],</span><br><span class=\"line\">              [<span class=\"string\">&#x27;LHip&#x27;</span>, <span class=\"string\">&#x27;LKnee&#x27;</span>], [<span class=\"string\">&#x27;LKnee&#x27;</span>, <span class=\"string\">&#x27;LAnkle&#x27;</span>], [<span class=\"string\">&#x27;Nose&#x27;</span>, <span class=\"string\">&#x27;REye&#x27;</span>], [<span class=\"string\">&#x27;REye&#x27;</span>, <span class=\"string\">&#x27;REar&#x27;</span>],</span><br><span class=\"line\">              [<span class=\"string\">&#x27;Nose&#x27;</span>, <span class=\"string\">&#x27;LEye&#x27;</span>], [<span class=\"string\">&#x27;LEye&#x27;</span>, <span class=\"string\">&#x27;LEar&#x27;</span>], [<span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;Nose&#x27;</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">pose_detection</span>(<span class=\"params\">image, inWidth=<span class=\"number\">368</span>, inHeight=<span class=\"number\">368</span>, scale=<span class=\"number\">0.003922</span>, mean=(<span class=\"params\"><span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span></span>), swapRB=<span class=\"literal\">False</span>, crop=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    :param image: 输入的图像数据</span></span><br><span class=\"line\"><span class=\"string\">    :param inWidth: 输入图像的宽度，默认为368</span></span><br><span class=\"line\"><span class=\"string\">    :param inHeight: 输入图像的高度，默认为368</span></span><br><span class=\"line\"><span class=\"string\">    :param scale: 图像缩放因子，默认为0.003922</span></span><br><span class=\"line\"><span class=\"string\">    :param mean: 图像均值，默认为(0, 0, 0)</span></span><br><span class=\"line\"><span class=\"string\">    :param swapRB: 是否交换图像通道顺序，默认为False</span></span><br><span class=\"line\"><span class=\"string\">    :param crop: 是否进行裁剪，默认为False</span></span><br><span class=\"line\"><span class=\"string\">    :return: key_points：关键点坐标数组，get_vertex_coordinates(key_points)的结果：顶点坐标数组</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 读取输入的图像数据</span></span><br><span class=\"line\">    image = cv2.imread(img_path)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> image.shape[<span class=\"number\">0</span>] &gt; <span class=\"number\">800</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 如果图像的高度大于800，按比例缩放到高度为800</span></span><br><span class=\"line\">        image = cv2.resize(image, (<span class=\"built_in\">int</span>(image.shape[<span class=\"number\">1</span>] * <span class=\"number\">800</span> / image.shape[<span class=\"number\">0</span>]), <span class=\"number\">800</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 对输入图像进行预处理，生成blob对象</span></span><br><span class=\"line\">    blob = cv2.dnn.blobFromImage(image, scale, (inWidth, inHeight), mean, swapRB, crop)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 输入blob到神经网络中进行推断</span></span><br><span class=\"line\">    net.setInput(blob)</span><br><span class=\"line\">    <span class=\"comment\"># 获取输出结果</span></span><br><span class=\"line\">    output = net.forward()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 显示检测结果并添加关键点名称</span></span><br><span class=\"line\">    H = output.shape[<span class=\"number\">2</span>]</span><br><span class=\"line\">    W = output.shape[<span class=\"number\">3</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 初始化关键点坐标数组</span></span><br><span class=\"line\">    keypoints = [(<span class=\"number\">0</span>, <span class=\"number\">0</span>)] * <span class=\"built_in\">len</span>(body_parts)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 遍历输出结果，获取每个关键点的置信度和坐标</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, part_name <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(body_parts):</span><br><span class=\"line\">        confidenceMap = output[<span class=\"number\">0</span>, i, :, :]</span><br><span class=\"line\">        _, conf, _, point = cv2.minMaxLoc(confidenceMap)</span><br><span class=\"line\">        x = <span class=\"built_in\">int</span>((image.shape[<span class=\"number\">1</span>] * point[<span class=\"number\">0</span>]) / W)</span><br><span class=\"line\">        y = <span class=\"built_in\">int</span>((image.shape[<span class=\"number\">0</span>] * point[<span class=\"number\">1</span>]) / H)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> conf &gt; <span class=\"number\">0.1</span> <span class=\"keyword\">and</span> (x, y) != (<span class=\"number\">0</span>, <span class=\"number\">0</span>):</span><br><span class=\"line\">            <span class=\"built_in\">print</span>((x, y))</span><br><span class=\"line\">            <span class=\"comment\"># 将符合条件的关键点坐标保存到数组中</span></span><br><span class=\"line\">            keypoints[i] = (x, y)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 在图像上显示关键点</span></span><br><span class=\"line\">            cv2.circle(image, (x, y), <span class=\"number\">5</span>, (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>), -<span class=\"number\">1</span>)</span><br><span class=\"line\">            cv2.putText(image, <span class=\"string\">&quot;&#123;&#125;&quot;</span>.<span class=\"built_in\">format</span>(part_name), (x, y + <span class=\"number\">30</span>),</span><br><span class=\"line\">                        cv2.FONT_HERSHEY_SIMPLEX, <span class=\"number\">0.5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\">            cv2.putText(image, <span class=\"string\">&quot;(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(x, y), (x, y),</span><br><span class=\"line\">                        cv2.FONT_HERSHEY_SIMPLEX, <span class=\"number\">0.5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 将关键点两两相连并绘制到图像中</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> pair <span class=\"keyword\">in</span> POSE_PAIRS:</span><br><span class=\"line\">        part_a = pair[<span class=\"number\">0</span>]</span><br><span class=\"line\">        part_b = pair[<span class=\"number\">1</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> part_a <span class=\"keyword\">in</span> body_parts.keys() <span class=\"keyword\">and</span> part_b <span class=\"keyword\">in</span> body_parts.keys():</span><br><span class=\"line\">            id_a = body_parts[part_a]</span><br><span class=\"line\">            id_b = body_parts[part_b]</span><br><span class=\"line\">            <span class=\"keyword\">if</span> keypoints[id_a][<span class=\"number\">0</span>] != <span class=\"number\">0</span> <span class=\"keyword\">and</span> keypoints[id_a][<span class=\"number\">1</span>] != <span class=\"number\">0</span> <span class=\"keyword\">and</span> keypoints[id_b][<span class=\"number\">0</span>] != <span class=\"number\">0</span> <span class=\"keyword\">and</span> keypoints[id_b][</span><br><span class=\"line\">                <span class=\"number\">1</span>] != <span class=\"number\">0</span>:</span><br><span class=\"line\">                cv2.line(image, keypoints[id_a], keypoints[id_b], colors[id_a], <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 去除关键点数组中的无效点（坐标为(0, 0)）</span></span><br><span class=\"line\">    keypoints = [item <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> keypoints <span class=\"keyword\">if</span> item != (<span class=\"number\">0</span>, <span class=\"number\">0</span>)]</span><br><span class=\"line\">    <span class=\"comment\"># 将关键点数组转换为NumPy数组</span></span><br><span class=\"line\">    key_points = np.array(keypoints)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 显示处理后的图像</span></span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">&quot;output&quot;</span>, image)</span><br><span class=\"line\">    cv2.waitKey(<span class=\"number\">0</span>)</span><br><span class=\"line\">    cv2.destroyAllWindows()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 打印关键点数组的类型</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"built_in\">type</span>(key_points))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 返回关键点数组和顶点坐标数组</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> key_points, get_vertex_coordinates(key_points)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_vertex_coordinates</span>(<span class=\"params\">arr</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    获取坐标数组中的四个顶点坐标</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    :param arr: 包含坐标点的二维数组，行表示点的数量，列表示每个点的坐标轴数量</span></span><br><span class=\"line\"><span class=\"string\">    :return: arr 一个按照顺时针方向排列的四个顶点的坐标数组</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 找到最上、最下、最左、最右四个点的索引</span></span><br><span class=\"line\">    <span class=\"comment\"># 找到y轴坐标最小的点的索引</span></span><br><span class=\"line\">    top_idx = np.argmin(arr[:, <span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到y轴坐标最大的点的索引</span></span><br><span class=\"line\">    bottom_idx = np.argmax(arr[:, <span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到x轴坐标最小的点的索引</span></span><br><span class=\"line\">    left_idx = np.argmin(arr[:, <span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到x轴坐标最大的点的索引</span></span><br><span class=\"line\">    right_idx = np.argmax(arr[:, <span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 输出最上、最下、最左和最右四个点的坐标</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最上坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[top_idx][<span class=\"number\">0</span>], arr[top_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最下坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[bottom_idx][<span class=\"number\">0</span>], arr[bottom_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最左坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[left_idx][<span class=\"number\">0</span>], arr[left_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最右坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[right_idx][<span class=\"number\">0</span>], arr[right_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 按上右下左顺时针方向创建一个包含四个顶点坐标的数组</span></span><br><span class=\"line\">    coordinates = np.array([</span><br><span class=\"line\">        [arr[top_idx][<span class=\"number\">0</span>], arr[top_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[right_idx][<span class=\"number\">0</span>], arr[right_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[bottom_idx][<span class=\"number\">0</span>], arr[bottom_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[left_idx][<span class=\"number\">0</span>], arr[left_idx][<span class=\"number\">1</span>]]</span><br><span class=\"line\">    ])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> coordinates</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    <span class=\"comment\"># 读取输入图像</span></span><br><span class=\"line\">    img_path = <span class=\"string\">&#x27;img/img.png&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 进行人体姿态估计</span></span><br><span class=\"line\">    key_points, vertex_coordinates = pose_detection(image=img_path)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;关键点坐标：&#x27;</span>, key_points)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;四个顶点坐标：&#x27;</span>, vertex_coordinates)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>这个代码可以满足单个人物的姿态识别，并且能够获取到每个关节点的坐标，可以依据坐标进行裁剪图片，但是存在多个人物的时候，会出现识别有误，效果并不是很理想。</p>\n<h2 id=\"多人物人体姿态识别\"><a class=\"markdownIt-Anchor\" href=\"#多人物人体姿态识别\"></a> 多人物人体姿态识别</h2>\n<p>然后再找到了 <a href=\"https://learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/\">LearnOpenCV</a> 的一个多人姿态检测实现的文章（译文可见<a href=\"https://blog.csdn.net/qq_27158179/article/details/82717821\">基于OpenCV使用OpenPose进行多个人体姿态估计</a> ）。</p>\n<p>主要实现方式是识别多个人物的关键点（例如鼻子），再通过关键点查找有效连接点，例如某人鼻子的左肩通常为这个人的左肩，他右边识别到的左肩则应该为另外一个人的左肩。通过亲和性方向进行识别和连接然后组合就能识别出来不同人物的姿态组，再通过姿态组绘制骨骼图就得到最终我们想要的多人物姿态识别。感兴趣的朋友可以自行查阅原文。</p>\n<p>以下是我实际可用的代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br><span class=\"line\">355</span><br><span class=\"line\">356</span><br><span class=\"line\">357</span><br><span class=\"line\">358</span><br><span class=\"line\">359</span><br><span class=\"line\">360</span><br><span class=\"line\">361</span><br><span class=\"line\">362</span><br><span class=\"line\">363</span><br><span class=\"line\">364</span><br><span class=\"line\">365</span><br><span class=\"line\">366</span><br><span class=\"line\">367</span><br><span class=\"line\">368</span><br><span class=\"line\">369</span><br><span class=\"line\">370</span><br><span class=\"line\">371</span><br><span class=\"line\">372</span><br><span class=\"line\">373</span><br><span class=\"line\">374</span><br><span class=\"line\">375</span><br><span class=\"line\">376</span><br><span class=\"line\">377</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">该文件主要用于识别人体姿态并输出最边缘坐标</span></span><br><span class=\"line\"><span class=\"string\">主要函数为 detect_pose</span></span><br><span class=\"line\"><span class=\"string\">不需要预览结果请注释 cv2.imshow 等相关代码即可</span></span><br><span class=\"line\"><span class=\"string\">依赖库</span></span><br><span class=\"line\"><span class=\"string\">opencv-python~=4.7.0.72</span></span><br><span class=\"line\"><span class=\"string\">numpy~=1.24.2</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设定模型文件路径和关键点数量等信息</span></span><br><span class=\"line\"><span class=\"comment\"># 模型结构文件</span></span><br><span class=\"line\">protoFile = <span class=\"string\">&quot;data//pose/coco/pose_deploy_linevec.prototxt&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 训练好的参数文件</span></span><br><span class=\"line\">weightsFile = <span class=\"string\">&quot;data/pose/coco/pose_iter_440000.caffemodel&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># COCO 数据集中人体关键点的数量</span></span><br><span class=\"line\">nPoints = <span class=\"number\">18</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># COCO 数据集中的人体关键点名称列表</span></span><br><span class=\"line\">keypointsMapping = [<span class=\"string\">&#x27;Nose&#x27;</span>, <span class=\"string\">&#x27;Neck&#x27;</span>, <span class=\"string\">&#x27;R-Shoulder&#x27;</span>, <span class=\"string\">&#x27;R-Elbow&#x27;</span>, <span class=\"string\">&#x27;R-Wrist&#x27;</span>, <span class=\"string\">&#x27;L-Shoulder&#x27;</span>, <span class=\"string\">&#x27;L-Elbow&#x27;</span>, <span class=\"string\">&#x27;L-Wrist&#x27;</span>, <span class=\"string\">&#x27;R-Hip&#x27;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&#x27;R-Knee&#x27;</span>, <span class=\"string\">&#x27;R-Ankle&#x27;</span>, <span class=\"string\">&#x27;L-Hip&#x27;</span>, <span class=\"string\">&#x27;L-Knee&#x27;</span>, <span class=\"string\">&#x27;L-Ankle&#x27;</span>, <span class=\"string\">&#x27;R-Eye&#x27;</span>, <span class=\"string\">&#x27;L-Eye&#x27;</span>, <span class=\"string\">&#x27;R-Ear&#x27;</span>, <span class=\"string\">&#x27;L-Ear&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义连接不同关键点之间的线段，即人体的姿势</span></span><br><span class=\"line\"><span class=\"comment\"># 在 COCO 输出格式中，关键点的编号从 0 开始，即第 0 个点表示 Nose，最后一个点是 L-Ear</span></span><br><span class=\"line\">POSE_PAIRS = [[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">1</span>, <span class=\"number\">5</span>], [<span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>], [<span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">6</span>, <span class=\"number\">7</span>],</span><br><span class=\"line\">              [<span class=\"number\">1</span>, <span class=\"number\">8</span>], [<span class=\"number\">8</span>, <span class=\"number\">9</span>], [<span class=\"number\">9</span>, <span class=\"number\">10</span>], [<span class=\"number\">1</span>, <span class=\"number\">11</span>], [<span class=\"number\">11</span>, <span class=\"number\">12</span>], [<span class=\"number\">12</span>, <span class=\"number\">13</span>],</span><br><span class=\"line\">              [<span class=\"number\">1</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">14</span>], [<span class=\"number\">14</span>, <span class=\"number\">16</span>], [<span class=\"number\">0</span>, <span class=\"number\">15</span>], [<span class=\"number\">15</span>, <span class=\"number\">17</span>],</span><br><span class=\"line\">              [<span class=\"number\">2</span>, <span class=\"number\">17</span>], [<span class=\"number\">5</span>, <span class=\"number\">16</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义每个 POSE_PAIRS 对应的 PAF 在输出中的索引</span></span><br><span class=\"line\"><span class=\"comment\"># pafs与POSE_PAIRS的索引，例如，对于POSE_PAIR（1,2），PAF位于输出的指数（31,32），类似，（1,5）-&gt;（39,40）等。</span></span><br><span class=\"line\"><span class=\"comment\"># PAF 表示 Part Affinity Fields，即用于描述关键点之间连接情况的向量场</span></span><br><span class=\"line\"><span class=\"comment\"># 在这里，使用了 COCO 数据集中提供的预训练模型，其输出结果包括关键点坐标和 PAF</span></span><br><span class=\"line\">mapIdx = [[<span class=\"number\">31</span>, <span class=\"number\">32</span>], [<span class=\"number\">39</span>, <span class=\"number\">40</span>], [<span class=\"number\">33</span>, <span class=\"number\">34</span>], [<span class=\"number\">35</span>, <span class=\"number\">36</span>], [<span class=\"number\">41</span>, <span class=\"number\">42</span>], [<span class=\"number\">43</span>, <span class=\"number\">44</span>],</span><br><span class=\"line\">          [<span class=\"number\">19</span>, <span class=\"number\">20</span>], [<span class=\"number\">21</span>, <span class=\"number\">22</span>], [<span class=\"number\">23</span>, <span class=\"number\">24</span>], [<span class=\"number\">25</span>, <span class=\"number\">26</span>], [<span class=\"number\">27</span>, <span class=\"number\">28</span>], [<span class=\"number\">29</span>, <span class=\"number\">30</span>],</span><br><span class=\"line\">          [<span class=\"number\">47</span>, <span class=\"number\">48</span>], [<span class=\"number\">49</span>, <span class=\"number\">50</span>], [<span class=\"number\">53</span>, <span class=\"number\">54</span>], [<span class=\"number\">51</span>, <span class=\"number\">52</span>], [<span class=\"number\">55</span>, <span class=\"number\">56</span>],</span><br><span class=\"line\">          [<span class=\"number\">37</span>, <span class=\"number\">38</span>], [<span class=\"number\">45</span>, <span class=\"number\">46</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># # 定义用于绘制不同连接线段的颜色，根据定义的姿势连接线段，每个连接线段对应一种颜色</span></span><br><span class=\"line\">colors = [[<span class=\"number\">0</span>, <span class=\"number\">100</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">100</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">100</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">100</span>, <span class=\"number\">255</span>],</span><br><span class=\"line\">          [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>], [<span class=\"number\">255</span>, <span class=\"number\">200</span>, <span class=\"number\">100</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>], [<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>], [<span class=\"number\">255</span>, <span class=\"number\">200</span>, <span class=\"number\">100</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>],</span><br><span class=\"line\">          [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">200</span>, <span class=\"number\">200</span>, <span class=\"number\">0</span>], [<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">200</span>, <span class=\"number\">200</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 存储检测出来的所有关键点坐标列表，用于后续计算顶点</span></span><br><span class=\"line\">points = []</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">detect_pose</span>(<span class=\"params\">image_path</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    检测姿势</span></span><br><span class=\"line\"><span class=\"string\">    :param image_path: 图片路径</span></span><br><span class=\"line\"><span class=\"string\">    :return: 返回 pose, points</span></span><br><span class=\"line\"><span class=\"string\">    其中 pose 为</span></span><br><span class=\"line\"><span class=\"string\">    points 为 按照顺时针方向排列（即上右下左）的四个最顶点的坐标数组</span></span><br><span class=\"line\"><span class=\"string\">    调用函数例子如下：</span></span><br><span class=\"line\"><span class=\"string\">    path = &quot;img/test.png&quot;</span></span><br><span class=\"line\"><span class=\"string\">    pose, points = detect_pose(path)</span></span><br><span class=\"line\"><span class=\"string\">    print(points)</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 创建一个解析器</span></span><br><span class=\"line\">    parser = argparse.ArgumentParser(description=<span class=\"string\">&#x27;运行关键点检测&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 添加参数</span></span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">&quot;--device&quot;</span>, default=<span class=\"string\">&quot;cpu&quot;</span>, <span class=\"built_in\">help</span>=<span class=\"string\">&quot;推理设备&quot;</span>)</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">&quot;--image_file&quot;</span>, default=image_path, <span class=\"built_in\">help</span>=<span class=\"string\">&quot;输入图像&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析参数</span></span><br><span class=\"line\">    args = parser.parse_args()</span><br><span class=\"line\">    <span class=\"comment\"># 读取输入图像</span></span><br><span class=\"line\">    image1 = cv2.imread(args.image_file)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">getKeypoints</span>(<span class=\"params\">probMap, threshold=<span class=\"number\">0.1</span></span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        从输入的概率图（即 probMap）中提取关键点信息</span></span><br><span class=\"line\"><span class=\"string\">        :param probMap:  概率图</span></span><br><span class=\"line\"><span class=\"string\">        :param threshold: 二值化概率图时所采用的阈值，默认为 0.1</span></span><br><span class=\"line\"><span class=\"string\">        值较小时，可以提取出更多的关键点，但可能会包含一些噪声或冗余信息</span></span><br><span class=\"line\"><span class=\"string\">        值较大时，可以减少关键点的数量，但可能会漏掉一些有用信息</span></span><br><span class=\"line\"><span class=\"string\">        :return: 关键点列表</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"comment\"># 对概率图进行高斯模糊，以去除噪声。</span></span><br><span class=\"line\">        mapSmooth = cv2.GaussianBlur(probMap, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), <span class=\"number\">0</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 二值化概率图，生成一个二值掩模</span></span><br><span class=\"line\">        mapMask = np.uint8(mapSmooth &gt; threshold)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 寻找轮廓</span></span><br><span class=\"line\">        contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class=\"line\"></span><br><span class=\"line\">        keypoints = []</span><br><span class=\"line\">        <span class=\"comment\"># 针对每个轮廓寻找最大值</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> cnt <span class=\"keyword\">in</span> contours:</span><br><span class=\"line\">            <span class=\"comment\"># 构造一个与原图大小一致的全黑图像</span></span><br><span class=\"line\">            blobMask = np.zeros(mapMask.shape)</span><br><span class=\"line\">            <span class=\"comment\"># 在全黑图像上填充轮廓，轮廓内部的像素值为 1，其余像素值为 0</span></span><br><span class=\"line\">            blobMask = cv2.fillConvexPoly(blobMask, cnt, <span class=\"number\">1</span>)</span><br><span class=\"line\">            <span class=\"comment\"># 计算概率图中对应区域的最大值和坐标， 将概率图与二值图像相乘，得到关键点所在区域的图像</span></span><br><span class=\"line\">            maskedProbMap = mapSmooth * blobMask</span><br><span class=\"line\">            <span class=\"comment\"># 在关键点所在区域的图像中，寻找最大值及其坐标，即关键点的位置</span></span><br><span class=\"line\">            _, maxVal, _, maxLoc = cv2.minMaxLoc(maskedProbMap)</span><br><span class=\"line\">            <span class=\"comment\"># 在关键点列表中加入当前关键点的坐标和对应概率</span></span><br><span class=\"line\">            keypoints.append(maxLoc + (probMap[maxLoc[<span class=\"number\">1</span>], maxLoc[<span class=\"number\">0</span>]],))</span><br><span class=\"line\">            <span class=\"comment\"># 冗余存储各关键点坐标，用于下面计算顶点坐标</span></span><br><span class=\"line\">            points.append(maxLoc)</span><br><span class=\"line\">        <span class=\"comment\"># 返回关键点列表</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> keypoints</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">getValidPairs</span>(<span class=\"params\">output</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        在所有检测到的人中，寻找有效连接关系</span></span><br><span class=\"line\"><span class=\"string\">        :param output: 检测到的人体内容</span></span><br><span class=\"line\"><span class=\"string\">        :return: 有效连接关系列表，无效连接关系列表</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"comment\"># 存储有效连接关系</span></span><br><span class=\"line\">        valid_pairs = []</span><br><span class=\"line\">        <span class=\"comment\"># 存储无效连接关系</span></span><br><span class=\"line\">        invalid_pairs = []</span><br><span class=\"line\">        <span class=\"comment\"># 插值采样点数目</span></span><br><span class=\"line\">        n_interp_samples = <span class=\"number\">10</span></span><br><span class=\"line\">        <span class=\"comment\"># PAF 对齐阈值</span></span><br><span class=\"line\">        paf_score_th = <span class=\"number\">0.1</span></span><br><span class=\"line\">        <span class=\"comment\"># 有效连接容忍度阈值</span></span><br><span class=\"line\">        conf_th = <span class=\"number\">0.7</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 对于每个 POSE_PAIR 进行如下处理</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(mapIdx)):</span><br><span class=\"line\">            <span class=\"comment\"># 获取该连线关系相关联的两个 PAF</span></span><br><span class=\"line\">            pafA = output[<span class=\"number\">0</span>, mapIdx[k][<span class=\"number\">0</span>], :, :]</span><br><span class=\"line\">            pafB = output[<span class=\"number\">0</span>, mapIdx[k][<span class=\"number\">1</span>], :, :]</span><br><span class=\"line\">            <span class=\"comment\"># 调整 PAF 的大小为原始图像的大小</span></span><br><span class=\"line\">            pafA = cv2.resize(pafA, (frameWidth, frameHeight))</span><br><span class=\"line\">            pafB = cv2.resize(pafB, (frameWidth, frameHeight))</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 获取第一条连线关系和第二条连线关系的关键点</span></span><br><span class=\"line\">            candA = detected_keypoints[POSE_PAIRS[k][<span class=\"number\">0</span>]]</span><br><span class=\"line\">            candB = detected_keypoints[POSE_PAIRS[k][<span class=\"number\">1</span>]]</span><br><span class=\"line\">            <span class=\"comment\"># 连线关系的关键点数目</span></span><br><span class=\"line\">            nA = <span class=\"built_in\">len</span>(candA)</span><br><span class=\"line\">            nB = <span class=\"built_in\">len</span>(candB)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 如果检测到了该连线关系的关键点，遍历所有关键点，计算距离向量并进行插值</span></span><br><span class=\"line\">            <span class=\"comment\"># 最后根据公式计算连接得分，并判断连接是否有效</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (nA != <span class=\"number\">0</span> <span class=\"keyword\">and</span> nB != <span class=\"number\">0</span>):</span><br><span class=\"line\">                valid_pair = np.zeros((<span class=\"number\">0</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\">                <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(nA):</span><br><span class=\"line\">                    max_j = -<span class=\"number\">1</span></span><br><span class=\"line\">                    maxScore = -<span class=\"number\">1</span></span><br><span class=\"line\">                    found = <span class=\"number\">0</span></span><br><span class=\"line\">                    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(nB):</span><br><span class=\"line\">                        <span class=\"comment\"># 计算两个关键点之间的向量 d_ij</span></span><br><span class=\"line\">                        d_ij = np.subtract(candB[j][:<span class=\"number\">2</span>], candA[i][:<span class=\"number\">2</span>])</span><br><span class=\"line\">                        <span class=\"comment\"># 计算 d_ij 的模长</span></span><br><span class=\"line\">                        norm = np.linalg.norm(d_ij)</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> norm:</span><br><span class=\"line\">                            <span class=\"comment\"># 归一化处理</span></span><br><span class=\"line\">                            d_ij = d_ij / norm</span><br><span class=\"line\">                        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                            <span class=\"keyword\">continue</span></span><br><span class=\"line\">                        <span class=\"comment\"># # 对连接中介进行插值，生成 n_interp_samples 个采样点  p(u)</span></span><br><span class=\"line\">                        interp_coord = <span class=\"built_in\">list</span>(<span class=\"built_in\">zip</span>(np.linspace(candA[i][<span class=\"number\">0</span>], candB[j][<span class=\"number\">0</span>], num=n_interp_samples),</span><br><span class=\"line\">                                                np.linspace(candA[i][<span class=\"number\">1</span>], candB[j][<span class=\"number\">1</span>], num=n_interp_samples)))</span><br><span class=\"line\">                        <span class=\"comment\"># # 查询 PAF 值 L(p(u))</span></span><br><span class=\"line\">                        paf_interp = []</span><br><span class=\"line\">                        <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(interp_coord)):</span><br><span class=\"line\">                            paf_interp.append([pafA[<span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(interp_coord[k][<span class=\"number\">1</span>])), <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(interp_coord[k][<span class=\"number\">0</span>]))],</span><br><span class=\"line\">                                               pafB[<span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(interp_coord[k][<span class=\"number\">1</span>])), <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(interp_coord[k][<span class=\"number\">0</span>]))]])</span><br><span class=\"line\">                        <span class=\"comment\"># 计算连接得分 E</span></span><br><span class=\"line\">                        paf_scores = np.dot(paf_interp, d_ij)</span><br><span class=\"line\">                        avg_paf_score = <span class=\"built_in\">sum</span>(paf_scores) / <span class=\"built_in\">len</span>(paf_scores)</span><br><span class=\"line\"></span><br><span class=\"line\">                        <span class=\"comment\"># 如果插值采样点中对齐 PAF 向量的比例高于阈值，则判定为有效连接关系</span></span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (<span class=\"built_in\">len</span>(np.where(paf_scores &gt; paf_score_th)[<span class=\"number\">0</span>]) / n_interp_samples) &gt; conf_th:</span><br><span class=\"line\">                            <span class=\"keyword\">if</span> avg_paf_score &gt; maxScore:</span><br><span class=\"line\">                                max_j = j</span><br><span class=\"line\">                                maxScore = avg_paf_score</span><br><span class=\"line\">                                found = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">                    <span class=\"comment\"># 将有效连接信息添加到列表中</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> found:</span><br><span class=\"line\">                        valid_pair = np.append(valid_pair, [[candA[i][<span class=\"number\">3</span>], candB[max_j][<span class=\"number\">3</span>], maxScore]], axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"comment\"># 将有效连接信息存入全局列表中</span></span><br><span class=\"line\">                valid_pairs.append(valid_pair)</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"comment\"># 没有检测到关键点，说明连接无效</span></span><br><span class=\"line\">                <span class=\"built_in\">print</span>(<span class=\"string\">&quot;没有连接 : k = &#123;&#125;&quot;</span>.<span class=\"built_in\">format</span>(k))</span><br><span class=\"line\">                invalid_pairs.append(k)</span><br><span class=\"line\">                valid_pairs.append([])</span><br><span class=\"line\">        <span class=\"comment\"># 返回有效连接关系列表和无效连接关系列表</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> valid_pairs, invalid_pairs</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">getPersonwiseKeypoints</span>(<span class=\"params\">valid_pairs, invalid_pairs</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        遍历所有有效连接关系，将其对应的关键点分配给不同的人，并计算出每个人在当前姿态下的得分。</span></span><br><span class=\"line\"><span class=\"string\">        这样可以更为合适地去描绘人体姿态，减少出现 A 的左眼连结到 B 的右眼的情况</span></span><br><span class=\"line\"><span class=\"string\">        :param valid_pairs:  有效连接关系列表</span></span><br><span class=\"line\"><span class=\"string\">        :param invalid_pairs: 无效连接关系列表</span></span><br><span class=\"line\"><span class=\"string\">        :return: 个性化关键点数组</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"comment\"># 每一行最后一个元素是总得分</span></span><br><span class=\"line\">        personwiseKeypoints = -<span class=\"number\">1</span> * np.ones((<span class=\"number\">0</span>, <span class=\"number\">19</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 遍历所有有效连接关系</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(mapIdx)):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> k <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> invalid_pairs:</span><br><span class=\"line\">                <span class=\"comment\"># partAs 和 partBs 分别是相互连接的两个关节点</span></span><br><span class=\"line\">                partAs = valid_pairs[k][:, <span class=\"number\">0</span>]</span><br><span class=\"line\">                partBs = valid_pairs[k][:, <span class=\"number\">1</span>]</span><br><span class=\"line\">                indexA, indexB = np.array(POSE_PAIRS[k])</span><br><span class=\"line\">                <span class=\"comment\"># 将 B 的分数加到 A 所在行的总得分中，或创建一个新行</span></span><br><span class=\"line\">                <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(valid_pairs[k])):</span><br><span class=\"line\">                    found = <span class=\"number\">0</span></span><br><span class=\"line\">                    person_idx = -<span class=\"number\">1</span></span><br><span class=\"line\">                    <span class=\"comment\"># 在已有的姿态中查找 partA。</span></span><br><span class=\"line\">                    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(personwiseKeypoints)):</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> personwiseKeypoints[j][indexA] == partAs[i]:</span><br><span class=\"line\">                            person_idx = j</span><br><span class=\"line\">                            found = <span class=\"number\">1</span></span><br><span class=\"line\">                            <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">                    <span class=\"comment\"># 如果在当前姿态中找到了与 partA 相关联的关键点，则将 partB 添加到该行。</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> found:</span><br><span class=\"line\">                        personwiseKeypoints[person_idx][indexB] = partBs[i]</span><br><span class=\"line\">                        <span class=\"comment\"># 在该姿态下，添加 partB 的关键点分数以及连接得分到该行的总得分中。</span></span><br><span class=\"line\">                        personwiseKeypoints[person_idx][-<span class=\"number\">1</span>] += keypoints_list[partBs[i].astype(<span class=\"built_in\">int</span>), <span class=\"number\">2</span>] + \\</span><br><span class=\"line\">                                                               valid_pairs[k][i][</span><br><span class=\"line\">                                                                   <span class=\"number\">2</span>]</span><br><span class=\"line\">                    <span class=\"comment\"># 如果当前姿态中不存在与 partA 相关联的关键点，则创建一个新姿态</span></span><br><span class=\"line\">                    <span class=\"keyword\">elif</span> <span class=\"keyword\">not</span> found <span class=\"keyword\">and</span> k &lt; <span class=\"number\">17</span>:</span><br><span class=\"line\">                        row = -<span class=\"number\">1</span> * np.ones(<span class=\"number\">19</span>)</span><br><span class=\"line\">                        row[indexA] = partAs[i]</span><br><span class=\"line\">                        row[indexB] = partBs[i]</span><br><span class=\"line\">                        <span class=\"comment\"># 在该姿态下，将两个关键点的关键点分数 scores 以及连接得分加起来作为该行的总得分。</span></span><br><span class=\"line\">                        row[-<span class=\"number\">1</span>] = <span class=\"built_in\">sum</span>(keypoints_list[valid_pairs[k][i, :<span class=\"number\">2</span>].astype(<span class=\"built_in\">int</span>), <span class=\"number\">2</span>]) + valid_pairs[k][i][<span class=\"number\">2</span>]</span><br><span class=\"line\">                        personwiseKeypoints = np.vstack([personwiseKeypoints, row])</span><br><span class=\"line\">        <span class=\"comment\"># 最终返回一个二维数组，每行代表一个人体姿态，每列代表一个关节点。</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> personwiseKeypoints</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 获取图像的宽度和高度</span></span><br><span class=\"line\">    frameWidth = image1.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    frameHeight = image1.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    t = time.time()</span><br><span class=\"line\">    <span class=\"comment\"># 从磁盘上读取预训练模型</span></span><br><span class=\"line\">    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)</span><br><span class=\"line\">    <span class=\"comment\"># 指定运行模型的设备类型，如果使用CPU则设置为CPU，否则设置为GPU</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> args.device == <span class=\"string\">&quot;cpu&quot;</span>:</span><br><span class=\"line\">        net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;使用 CPU&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> args.device == <span class=\"string\">&quot;gpu&quot;</span>:</span><br><span class=\"line\">        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)</span><br><span class=\"line\">        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;使用 GPU&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 固定输入图像的高度，并根据图像的宽高比来计算输入的宽度</span></span><br><span class=\"line\">    inHeight = <span class=\"number\">368</span></span><br><span class=\"line\">    inWidth = <span class=\"built_in\">int</span>((inHeight / frameHeight) * frameWidth)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 将输入图像转换为Blob格式，并进行归一化和缩放</span></span><br><span class=\"line\">    inpBlob = cv2.dnn.blobFromImage(image1, <span class=\"number\">1.0</span> / <span class=\"number\">255</span>, (inWidth, inHeight),</span><br><span class=\"line\">                                    (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), swapRB=<span class=\"literal\">False</span>, crop=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 将输入Blob传递给网络</span></span><br><span class=\"line\">    net.setInput(inpBlob)</span><br><span class=\"line\">    <span class=\"comment\"># 运行前馈传递，可以获取到识别的人脸</span></span><br><span class=\"line\">    output = net.forward()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;前馈传递所需时间 = &#123;&#125;&quot;</span>.<span class=\"built_in\">format</span>(time.time() - t))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 定义一个列表用于存储检测出的所有关键点</span></span><br><span class=\"line\">    detected_keypoints = []</span><br><span class=\"line\">    <span class=\"comment\"># 创建一个 shape 为 (0, 3) 的 numpy 数组，用于保存关键点的位置和 id</span></span><br><span class=\"line\">    keypoints_list = np.zeros((<span class=\"number\">0</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\">    <span class=\"comment\"># 初始化关键点 id</span></span><br><span class=\"line\">    keypoint_id = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"comment\"># 设置概率阈值</span></span><br><span class=\"line\">    threshold = <span class=\"number\">0.1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 遍历每个关键点</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> part <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(nPoints):</span><br><span class=\"line\">        <span class=\"comment\"># 获取关键点对应的概率图，并将其 resize 到与输入图像相同的大小</span></span><br><span class=\"line\">        probMap = output[<span class=\"number\">0</span>, part, :, :]</span><br><span class=\"line\">        probMap = cv2.resize(probMap, (image1.shape[<span class=\"number\">1</span>], image1.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 根据阈值获取该关键点的位置</span></span><br><span class=\"line\">        keypoints = getKeypoints(probMap, threshold)</span><br><span class=\"line\">        <span class=\"comment\"># 输出该关键点的位置信息</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Keypoints - &#123;&#125; : &#123;&#125;&quot;</span>.<span class=\"built_in\">format</span>(keypointsMapping[part], keypoints))</span><br><span class=\"line\">        <span class=\"comment\"># 存储关键点的位置和 id</span></span><br><span class=\"line\">        keypoints_with_id = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(keypoints)):</span><br><span class=\"line\">            keypoints_with_id.append(keypoints[i] + (keypoint_id,))</span><br><span class=\"line\">            keypoints_list = np.vstack([keypoints_list, keypoints[i]])</span><br><span class=\"line\">            keypoint_id += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">        detected_keypoints.append(keypoints_with_id)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 在原始图像上绘制所有检测出的关键点和 id</span></span><br><span class=\"line\">    frameClone = image1.copy()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(nPoints):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(detected_keypoints[i])):</span><br><span class=\"line\">            <span class=\"comment\"># 输出关键点对应的坐标和名称</span></span><br><span class=\"line\">            <span class=\"built_in\">print</span>(detected_keypoints[i][j][<span class=\"number\">0</span>:<span class=\"number\">2</span>])</span><br><span class=\"line\">            cv2.putText(frameClone, <span class=\"string\">&quot;&#123;&#125;&quot;</span>.<span class=\"built_in\">format</span>(keypointsMapping[i]), detected_keypoints[i][j][<span class=\"number\">0</span>:<span class=\"number\">2</span>],</span><br><span class=\"line\">                        cv2.FONT_HERSHEY_SIMPLEX, <span class=\"number\">0.5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\">            cv2.putText(frameClone, <span class=\"string\">&quot;(&#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(detected_keypoints[i][j]), detected_keypoints[i][j][<span class=\"number\">0</span>:<span class=\"number\">2</span>],</span><br><span class=\"line\">                        cv2.FONT_HERSHEY_SIMPLEX, <span class=\"number\">0.5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\">            cv2.circle(frameClone, detected_keypoints[i][j][<span class=\"number\">0</span>:<span class=\"number\">2</span>], <span class=\"number\">5</span>, colors[i], -<span class=\"number\">1</span>, cv2.LINE_AA)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 在原始图像上绘制每条相邻关键点之间的连线，描绘人体的姿态</span></span><br><span class=\"line\">    valid_pairs, invalid_pairs = getValidPairs(output)</span><br><span class=\"line\">    personwiseKeypoints = getPersonwiseKeypoints(valid_pairs, invalid_pairs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">17</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> n <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(personwiseKeypoints)):</span><br><span class=\"line\">            index = personwiseKeypoints[n][np.array(POSE_PAIRS[i])]</span><br><span class=\"line\">            <span class=\"keyword\">if</span> -<span class=\"number\">1</span> <span class=\"keyword\">in</span> index:</span><br><span class=\"line\">                <span class=\"keyword\">continue</span></span><br><span class=\"line\">            B = np.int32(keypoints_list[index.astype(<span class=\"built_in\">int</span>), <span class=\"number\">0</span>])</span><br><span class=\"line\">            A = np.int32(keypoints_list[index.astype(<span class=\"built_in\">int</span>), <span class=\"number\">1</span>])</span><br><span class=\"line\">            cv2.line(frameClone, (B[<span class=\"number\">0</span>], A[<span class=\"number\">0</span>]), (B[<span class=\"number\">1</span>], A[<span class=\"number\">1</span>]), colors[i], <span class=\"number\">3</span>, cv2.LINE_AA)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 可视化显示检测结果，仅供预览使用，这部分可注释</span></span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">&quot;关键点&quot;</span>, frameClone)</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">&quot;姿态检测&quot;</span>, frameClone)</span><br><span class=\"line\">    cv2.waitKey(<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 返回检测到的人体关键点和身体姿态的信息</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> personwiseKeypoints[<span class=\"number\">0</span>] <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(personwiseKeypoints) &gt; <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"literal\">None</span>, get_vertex_coordinates(points)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_vertex_coordinates</span>(<span class=\"params\">arr</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    获取坐标数组中的四个顶点坐标</span></span><br><span class=\"line\"><span class=\"string\">    :param arr: 包含坐标点的二维数组，行表示点的数量，列表示每个点的坐标轴数量</span></span><br><span class=\"line\"><span class=\"string\">    :return: arr 一个按照顺时针方向排列的四个顶点的坐标数组</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    arr = np.array(arr)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 找到最上、最下、最左、最右四个点的索引</span></span><br><span class=\"line\">    <span class=\"comment\"># 找到y轴坐标最小的点的索引</span></span><br><span class=\"line\">    top_idx = np.argmin(arr[:, <span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到y轴坐标最大的点的索引</span></span><br><span class=\"line\">    bottom_idx = np.argmax(arr[:, <span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到x轴坐标最小的点的索引</span></span><br><span class=\"line\">    left_idx = np.argmin(arr[:, <span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"comment\"># 找到x轴坐标最大的点的索引</span></span><br><span class=\"line\">    right_idx = np.argmax(arr[:, <span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 输出最上、最下、最左和最右四个点的坐标</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最上坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[top_idx][<span class=\"number\">0</span>], arr[top_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最下坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[bottom_idx][<span class=\"number\">0</span>], arr[bottom_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最左坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[left_idx][<span class=\"number\">0</span>], arr[left_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;最右坐标为：(&#123;&#125;, &#123;&#125;)&quot;</span>.<span class=\"built_in\">format</span>(arr[right_idx][<span class=\"number\">0</span>], arr[right_idx][<span class=\"number\">1</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 按上右下左顺时针方向创建一个包含四个顶点坐标的数组</span></span><br><span class=\"line\">    coordinates = np.array([</span><br><span class=\"line\">        [arr[top_idx][<span class=\"number\">0</span>], arr[top_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[right_idx][<span class=\"number\">0</span>], arr[right_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[bottom_idx][<span class=\"number\">0</span>], arr[bottom_idx][<span class=\"number\">1</span>]],</span><br><span class=\"line\">        [arr[left_idx][<span class=\"number\">0</span>], arr[left_idx][<span class=\"number\">1</span>]]</span><br><span class=\"line\">    ])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> coordinates</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    path = <span class=\"string\">&quot;../data/result.png&quot;</span></span><br><span class=\"line\">    pose, points = detect_pose(path)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;------------&#x27;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(points)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>结果返回了多个关键点和四个方向顶点坐标数组，可以看到效果还是很好的，可以满足业务需求了。</p>\n<h2 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h2>\n<blockquote>\n<p><a href=\"https://www.jianshu.com/p/3aa810b35a5d\">Github开源人体姿态识别项目OpenPose中文文档 - 简书</a></p>\n<p><a href=\"https://blog.csdn.net/qq_27158179/article/details/82717821\">基于OpenCV使用OpenPose进行多个人体姿态估计_qq_27158179的CSDN博客</a></p>\n<p><a href=\"https://learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/\">Multi Person Pose Estimation in OpenCV using OpenPose (learnopencv.com)</a></p>\n</blockquote>\n","categories":[{"name":"技术","path":"api/categories/技术.json"},{"name":"Python","path":"api/categories/Python.json"}],"tags":[{"name":"技术","path":"api/tags/技术.json"},{"name":"Python","path":"api/tags/Python.json"},{"name":"OpenCV","path":"api/tags/OpenCV.json"},{"name":"OpenPose","path":"api/tags/OpenPose.json"},{"name":"人体姿态识别","path":"api/tags/人体姿态识别.json"}]}